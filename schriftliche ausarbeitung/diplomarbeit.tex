%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%% Template für Studien-, Diplom-, Bachelor- und Masterarbeiten %%
%%                 am Lehrstuhl ISE der CAU Kiel                %%
%%                                                              %%
%%                              17.10.2006                      %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
%% Stellen, an denen noch Daten eingetragen werden müssen,
%% sind mit ** gekennzeichnet.

%% Größe: A4, doppelseitig 
\documentclass[twoside,a4paper,BCOR1.0cm]{scrbook}

\usepackage{ifpdf}

\usepackage{ae,aecompl}
\usepackage[latin1]{inputenc} %% unter Linux/Unix "ansinew" evtl. durch "latin1" ersetzen
\usepackage{amsthm}
\usepackage{amsfonts}
\newtheorem{definition}{Definition}
%%\usepackage{ngerman}
%%\usepackage{url}

%% Falls PicTeX-Grafiken (z.B. aus XFig) eingebunden werden sollen
%%\usepackage{pictexwd}

%% einige mathematische Symbole (falls benötigt)
%%\usepackage{stmaryrd}
\usepackage[intlimits]{amsmath}
%%\usepackage{amssymb}

%% für listings-Umgebungen und Algorithmen
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}

%%\renewcommand{\listalgorithmname}{Listingsverzeichnis} 

%% Literatur-Verzeichnis
\usepackage{natbib}
\bibpunct{[}{]}{;}{a}{,}{,}

\ifpdf
  % für Grafiken
  \usepackage[pdftex]{graphicx}
  
  % Verweise in PDF
  \usepackage[pdftex,plainpages=false]{hyperref}
  \pdfcompresslevel=9  

  % Metadaten des Dokuments
  \hypersetup{%
    a4paper,
    pdftitle = {A Contribution to Rating and Recommendation Systems: Concepts, Development and Evaluation},
    pdfsubject = {** Hier eine Beschreibung eintragen **},
    pdfkeywords = {** Hier Schlagwörter eintragen **},
    pdfauthor = {Oliver Diestel},
    % pdfpagemode = None, UseThumbs, UseOutlines, FullScreen,
    % pdfstartpage = ,
    % pdfstartview = 
  }
\else
  \usepackage[plainpages=false]{hyperref}
  \usepackage{graphicx}
\fi    
\usepackage{todonotes}
\usepackage{tikz}
%\usetikzlibrary{arrows,automata,positioning}
\usetikzlibrary{%
  arrows,%
  shapes.misc,% wg. rounded rectangle
  shapes.arrows,%
  chains,%
  matrix,%
  positioning,% wg. " of "
  scopes,%
  decorations.pathmorphing,% /pgf/decoration/random steps | erste Graphik
  shadows,
  automata
}



\setlength{\parindent}{0cm}

\begin{document}
\ifpdf
  \DeclareGraphicsExtensions{.jpg, .pdf, .mps, .png}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

\renewcommand{\textfraction}{0.1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                          Titelseite                          %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{empty}

\begin{center}
{\huge \it Diplomarbeit}

\vspace{2cm}

{\Large \bf A Contribution to Rating and Recommendation Systems: Concepts, Development and Evaluation}

\vspace{2.25cm}

%%\includegraphics[height=4cm]{CAU-Siegel}

\vspace{2.25cm}

{\large 
Christian-Albrechts-Universität zu Kiel \\
Institut für Informatik  \\
Lehrstuhl Technologie der Informationssysteme
}

\end{center}

\vspace{2cm}

\begin{tabular}{ll}
angefertigt von:             & {\bf Oliver Diestel} \\
betreuender Hochschullehrer: & ** Name des betreuenden Hochschullehrers ** \\%
%                              z.B. Prof. Dr. rer. nat. habil. Bernhard Thalheim 
%                              oder Prof. Dr. rer. nat. habil. Hans-Joachim Klein
Betreuer:                    & ** Name des Betreuers ** 
\end{tabular}

\vspace{1cm}

\begin{center}
Kiel, ** Datum der Abgabe **
\end{center}


\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                      Aufgabenstellung                        %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pagestyle{plain}
% \chapter*{Aufgabe}

% \begin{tabular}{ll}
% {\bf Name, Vorname: }               & ** Name, Vorname **                            \\
% {\bf Immatrikulations-Nr: }         & ** Immatrikulations-Nr **                      \\
% {\bf Studiengang: }                 & ** Studiengang **                              \\
%                                     &                                                \\
% {\bf betreuender Hochschullehrer: } & ** Name des Hochschullehrers **   \\
% {\bf Betreuer: }                    & ** Name des Betreuers **                       \\
% {\bf Institut: }                    & Institut für Informatik  \\
% {\bf Arbeitsgruppe: }               & Technologie der Informationssysteme            \\
%                                     &                                                \\
% {\bf Beginn am: }                   & ** Datum des Beginns **                        \\
% {\bf Einzureichen bis: }            & ** Abgabetermin **                           
% \end{tabular}

% \vspace{1cm}

% {\bf Aufgabenstellung:}

% \vspace{0.5cm}

% ** Text der Aufgabenstellung **

% \pagenumbering{roman}
% \setcounter{page}{1}
% \cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                Selbstständigkeitserklärung                   %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Selbstständigkeitserklärung}

\vspace{1.5cm}

Ich erkläre hiermit, dass ich die vorliegende Arbeit selbstständig und nur unter Verwendung der angegebenen Literatur und Hilfsmittel angefertigt habe.

\vspace{2cm}
............................................................... \\
** eigener Name **

\thispagestyle{plain}
\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Inhaltsverzeichnis                       %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Abbildungsverzeichnis                    %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listoffigures

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Tabellenverzeichnis                      %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listoftables

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                   Algorithmenverzeichnis                     %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listofalgorithms

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%              Liste der verwendeten Abkürzungen               %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abkürzungen}


\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                       Text der Arbeit                        %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abstract}
\cleardoublepage

\pagestyle{headings}
\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{Introduction}

\section{Related Work}
\section{Contributions}
\section{Overview}

%%purpose of a qa system why did I choose Askbot? 
%%how I'm getting ratings for the items
%discuss qa system, rating system, tagging system, item based, svd based, bringing it all together, display recommendations on a website
\chapter{Concepts}
%\todo{better introduction for 2}
%The basic approach of the system is that it should be easy to integrate the technology into an existing system and that each described concept should work as a stand alone technology.
%present
This chapter outlines the concepts that are integrated in the developed system.
The first section deals with the approach of a \emph{question and answer site} and explains the necessity of such a system. 
The second section is about the differences between implicit and explicit ratings and the different sources of implicit ratings.
Moreover this section describes the implemented concept of collecting implicit ratings.
The third section treats the automated tagging process that is used to connect the questions and answers with the recommendation system.
The fourth section is a discussion about the different types of recommendation systems.
This leads to the analysis of the different techniques of collective recommendations and explains how these techniques are used in the final system.
Finally the last section presents the relationship of the individual concepts from the previous sections.
\section{Question and Answer Site}
A question and answer site is a website that has only one focus namely getting the right answer for a question.
Therefore a user can ask a question. 
This question should be precise enough and include all information that another user needs to be able to write a correct answer to the question without asking for more details.
So, it is not a discussion forum but a website in which every answer only refers to the original question.
Then the user who started the question can mark one answer as correct.
This question and answer site should make the information retrieval process on a website publicly accessible.
Therefore all users are able to read all questions and answers and can support domain experts by answering questions.
For each question on the site there is exactly one answer marked as correct, thus, it is possible to recommend the questions with the correct answers to users who visit a website with the same subject.
This recommendation process should increase the user interaction with the website.
Moreover, it should help the user to understand the content which he is interested in.
Such question and answer sites are widely spread on the internet and there exists a couple of open source implementations that can be used for free.
Some of such open source implementations are askbot.com, discourse.org, lampcms.com and osqa.net.
They all work and almost look the same.
However, they use different technologies and some are more mature than others.
The open source variant that is in use for the implemented system is askbot.com.
It is build with the \emph{django web framework} and actively maintained since 2011.
%\todo{why did I choose askbot some screenshots}

%explain the function and idea of a qa system, explain askbot, explain why you choosed askbot and how to integrate it.
Henceforth, for better understanding, the word \emph{item} will be used instead of question and answer for an element that should be recommended.
\newpage
\section{Rating System}
In order to be able to recommend items to users it is important to understand what items a user likes.
For the purpose of such a task a rating scale ranging from 1, strongly disliked, to 5, strongly liked, is used.
There are two possible forms for retrieving ratings namely implicit ratings and explicit ratings. 
The latter are those in which a user is explicitly asked for his opinion on a specific item.
Implicit ratings are those in which a system generates a rating according to the actions of a user.
Anyhow, according to the book \emph{recommender systems an introduction} [\citet{recommender2011}] the explicit user ratings are usually not well accepted if a direct benefit is not visible to the user. 
Furthermore, the explicit ratings might disturb the user experience of a website.
Adding the explicit ratings with visible benefits to an existing \emph{question and answer website} would require too much customization, because in case the \emph{question and answer website} is replaced by a different open source version or an own implementation the explicit ratings with visible benefits have to be added again.
Therefore it is a good approach to use implicit ratings to collect the interest of a user.
The research group of \citet{claypool2001} developed a web browser that monitors user interactions and afterwards asks a user how he would rate the page.
Thereby it compares user interactions with explicit ratings.
\citet{claypool2001} build their results on a field experiment of over 80 people browsing over 2500 Web pages.
The user interactions they measured with their web browser are presented below.

\subsection{The time a user spends on a website}
The team of \emph{Claypool et al} measured the time a user spends on a website as a first indicator that the user works with the site.
The idea behind this method is that the more time the user takes to view the content of the website the more interesting the website is for him.
For this method a timer was used that measured the time a user spends on a website.
The timer starts after the website is completely loaded and stops when the user leaves the website or closes the window.
Additionally the timer is only active as long as the website is visible in the web browser.
They compared the time a user spends on a website with the explicit rating from the user this correlated about 70\% of the time.
So, they found out that the time a user spends on a website is a good indicator of interest.
For this reason this method is used as one implicit rating indicator in this thesis.
However one has to keep in mind, that the general time a website is open and visible needs to be relativized because one does not know whether the user is actually reading or interacting with the content of the current website.
Therefore other indicators where measured and included in \emph{Claypool's} research.
Which will be clarified in the following sections.

\subsection{The time the cursor is in motion}
Whereas the general time a user spends on a website already gives a good indication on how interesting the website is it is also important to measure how far the user actively engages with the website.
The use of methods that measure how active a user is on a website is important because these methods can indicate whether a user just opened a website and does not work with it or if he really engages with the content.
This time the cursor is in motion was measured by timing how long the mouse cursor changes its position inside the active browser window.
By comparing the explicit user ratings with the collected data they found out that the time a user moves the mouse cursor is proportional to the interest a user has in the website.
However, due to the fact that some users use the mouse heavily whilst reading the content of the website or looking at interesting objects such as diagrams or pictures, other users tend to only use the mouse in order to click on objects.
Consequently, it is not possible to tell how much a user is interested in the website by timing the cursor motion but it is only possible to tell which websites receive the least amount of interest.
Thus, in order to reflect the users interest more properly other ways to measure the active time on the website must be taken into account.

\subsection{The number of mouse clicks}
Another method of collecting user interactions that might correlate with the explicit rating of a user is the number of mouse clicks on a website.
The research team of \citet{claypool2001} thought that a high number of mouse clicks would be a sign that the website has links to interesting websites or objects and as such would be valuable to the users.
The collected data, however, showed that the number of mouse clicks on a website is not significantly different as though the user rated it with the highest or lowest rating. %\todo{check this sentence}
So, this method is not a good indicator for the users' interest.

\subsection{The time a user scrolls}
The last indicator they used was the time a user scrolls.
This is an important activity indicator because a user has to scroll in order to be able to see the whole content of a website.
The web browser the team of \emph{Claypool et al} developed measured the time a user scrolls a website by keys and by mouse.
They compared the data of the method of the field experiment with over 80 people with the explicit user ratings.
With that data they found out that both the measurement of user scrolls by keys and by mouse are on their own poor indicators of interest a combination of both methods is found to be a good indicator of interest.
This is explainable by the fact that some users prefer to scroll by using the mouse while others prefer the keyboard for such a task.
For this reason the time a user scrolls by mouse and by key was used in this thesis as an activity indicator.

\subsection{Concept}
As could be seen above the best sources of implicit ratings are the time a user spends on a web page and the amount a user scrolls on a web page according to \citet{claypool2001}.
These methods have an accuracy of about 70\% to the explicit user ratings.
This correlation between the implicit and explicit ratings can be explained by the fact that a user who is interested in an item takes a good look at an interesting website and reads the content that is presented on this site more carefully.
This process takes time, the user stays on the website longer and the user has to scroll in order to see the whole content of the website.


\begin{figure}[h]
  \centering
  \includegraphics[width=7.5cm]{image/scroll.png}
  \caption{Time spent scrolling \citet{claypool2001}}
  \label{pic:scrolltime}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=7.5cm]{image/time.png}
  \caption{Time spent on a page \citet{claypool2001}}
  \label{pic:time}
\end{figure}

%\todo{explanations of the images}


In order to collect implicit user ratings by timing how long the website is in focus, the truncated mean time all users spend on the item page is used as a benchmark.
\begin{definition}[Truncated Mean]
  The truncated mean (tm) is calculated the same way as the average mean after discarding a specific percentage of the highest and lowest values.
  Let $n \in \mathbb{N}$, V be a set of sorted numbers and p be a percentage with $0 \leq p < 0.5$.
  Let $k = np$ be the trimmed value, $r = n - 2k$ be the remaining values, $v_j \in V$ and $j \in \mathbb{N}$.
  Then the following formula represents the truncated mean.
  \begin{displaymath}
    Truncated Mean = \sum_{j=k+1}^{n-k}{v_j} \cdot \frac{1}{r}
  \end{displaymath}
\end{definition}
The percentages of the two rating processes result out of the two diagrams of figure ~\ref{pic:scrolltime} and figure ~\ref{pic:time}.%todo more detail
The following paragraph explains the rating of the item page in relation to the truncated mean time.
\todo{Add diagrams, maybe write the itemization as a text}
\begin{itemize}
  \item If the user spends less than 10\% of the truncated mean time on the item page it is used as a rating of 1.
  \item If the user spends less than the truncated mean time minus 20\% on the webpage it is used as a rating of 2.
  \item If the user spends plus minus 20\% of the truncated mean time on the item page, it is used as a rating of 3.
  \item If the user spends longer than the truncated mean time plus 20\% on the webpage it is used as a rating of 4.
\end{itemize}
A rating of 5 can only be achieved if a user does a predefined user interaction on the web page.
The reason behind this choice is that users tend to make breaks while surfing the internet.
Thus, the user leaves the current browser window open but is not actively working on this website.
Therefore it is possible that a user is on a break and the currently active browser window might not be interesting for him in that moment.
Such a predefined user interaction can be used as an indicator that a user likes an item.
A possible predefined user interaction could be an up-vote or the writing of a comment or answer. 
A similar scale is chosen for determining the rating of a user by the time a user scrolls.
\begin{itemize}
  \item If the user scrolls less than 40\% of the truncated mean time on the item page it is used as a rating of 1.
  \item If the user scrolls between 40\% and 80\% of the truncated mean time on the webpage it is used as a rating of 2.
  \item If the user spends plus minus 20\% of the truncated mean time on the item page, it is used as a rating of 3.
  \item If the user spends between the truncated mean time plus 20\% and 60\% on the webpage it is used as a rating of 4.
  \item If the user scrolls longer than the truncated mean time plus 60\% it is used as a rating of 5
\end{itemize}
Due to the fact that scrolling is an active process and the user has to be in front of the computer a rating of 5 is achievable in this method.
First of all both implicit ratings - the time a user spends on a website and the time a user scrolls - are determined separately.
Afterwards the average of both ratings is calculated and used as the total rating.
\begin{displaymath}
  total rating = \frac{rating_{time} + rating_{scroll}}{2}
\end{displaymath}
%\todo{add this to evaluation}The concept is build upon measurements of a field experiment of 75 students by \citet{claypool2001}, though due to the lack of time it wasn't possible to test this concept on a large user base.
If a user returns to an item site the new rating is added onto the previous rating with a maximum sum of 5.
This rating calculation results from the observation that users tend to revisit websites they were interested in in the past and which might help them with their current research.
It was considered to generally rate all websites that were revisited with the highest rating of 5 but this concept was abandoned because a user might be revisiting a formally uninteresting website unintentionally. %\todo{find a source}

As mentioned above \citet{claypool2001} research group bases its results on a field experiment of over 80 people browsing over 2500 Web pages.
The total rating concept is strongly build upon these results.
It would have been desirable to conduct a field experiment for the concept of the total rating but unfortunately due to the lack of time it was not possible.
%\todo{eligable to conduct such a field experiment in the future} 
%describe the google news approach, explain the changes that where made and why.

%%source of definitions
%%why start with finite automata why create deterministic finite automata and how
\newpage
\section{Tagging}
In order to recommend items with a matching subject on a website, the newly developed system needs to be able to filter the items based on their content.
Therefore the keywords of the item content are used as tags in order to reflect the content of the items. %\todo{improve}
%The content can be described with the use of tags, these tags are the keywords of the content.
In the context of economics the \emph{ZBW} provides the \emph{STW Thesaurus for Economics}.
The \emph{STW Thesaurus for Economics} provides vocabulary on any economic subject and includes about 19000 terms and 6000 standardized keywords which can be used to match words from a text.
It, thus, provides a good basis for the tagging process.
However, the \emph{STW Thesaurus for Economics} only includes the basic form of the words while excluding most of the words with affixation.
Due to this it is not sufficient to check whether the words from the items are equal to the words from the \emph{STW Thesaurus for Economics}.
So, the challenge for this tagging process is to find the correct words in the \emph{STW Thesaurus for Economics} even though the words from the item might not correspond directly to the words in the \emph{STW Thesaurus for Economics}.
One possible solution for such a task is to reduce each word from the text to its stem.\todo{definition stem}
Such a task is called stemming and is usually done by using predefined rules on the words. 
A rule is usually a combination of the minimum number of letters in a word, plus the suffix that should be changed and the replacement for the suffix.
More advanced algorithms might also use rules for prefix reduction and detecting irregular changes of the stem according to \emph{Caumanns A Fast and Simple Stemming Algorithm for German Words}.
For example a predefined rule might be '3+ies' $\rightarrow$ 'y'.
So, the word \emph{libraries} would be reduced to \emph{library}.
Thus it is important that the stemming algorithm has all necessary rules for each supported language.\\
Another challenge for using the stemming algorithm is that all words in the basis for the tagging process must be in the stem form. 
Otherwise the algorithm might reduce a word to its stem that would match in its original form.
Due to these maintenance problems it was decided that the stemming algorithm is not suitable for the developed system.
Another possible solution for the problem is to calculate the differences between the words from the text and the words from the basis for the tagging process.
This difference can be used as an indicator whether the words are similar or not.
If they are in a predefined difference range the words can be used as tags.%\todo{read this for a second time}
This creates the need for a metric that indicates the difference or distance between two words.
A practical metric for such a task is the \emph{levenshtein distance} which will be explained in the following section.
\subsection{Levenshtein Distance}

The \emph{levenshtein distance} calculates the minimum numbers of substitutions, insertions and deletions that are needed to change one word into another.
The following example explains the \emph{levenshtein distance} for the words \emph{library} and \emph{libraries}.
The algorithm has to perform two deletions and one substitution in order to create the word \emph{library} out of the word \emph{libraries}.
If it creates the word \emph{libraries} out of the word \emph{library} it has to perform a substitution and two insertions.
\begin{displaymath}
  {library \leftrightarrow librari \leftrightarrow librarie \leftrightarrow libraries}
\end{displaymath}
Both processes result in a \emph{levenshtein distance} of three.
So, the \emph{levenshtein distance} is zero if the words are equal and adds one to the result if it has to perform a substitution, an insertion or a deletion of a letter. 
For a more detailed description compare algorithm ~\ref{alg:levDist}.
% \todo{find better solution to move 'if'}
%   $levDist_{a,b}(i,j) = $
%   \begin{cases}
%     max(i,j) \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \text{if min(i,j) = 0} \\
%     min \begin{cases}
%         levDist_{a,b}(i-1, j)+1 \\
%         levDist_{a,b}(i, j-1)+1 & \text{else}\\
%         levDist_{a,b}(i-1, j-1) + [a_i \neq b_i] 
%       \end{cases}
%   \end{cases}\\
% This can be directly translated into a recursive algorithm. 
\begin{algorithm}
  \caption{Recursive Levenshtein Distance Algorithm}\label{alg:levDist}
  \begin{algorithmic}[1]
    \Procedure{LevenshteinDistance}{$s: String, t: String$}
    \State $lenS\gets length(s)$
    \If{lenS = 0}
      \State \textbf{return} $lenT$
    \EndIf
    \If{lenT = 0}
      \State \textbf{return} $lenS$
    \EndIf

    \If{s[lenS-1] = t[lenT-1]}\Comment{test if last characters of the strings match}
      \State $cost\gets 0$
    \Else
      \State $cost\gets 1$
    \EndIf

    \Comment{The first recursive call represents a deletion, the second represents an insertion and the third represents a substitution or a correct letter}
    \State \textbf{return} minimum of\par
    $LevenshteinDistance(s[0..lenS-1], t) +1,$\par 
    $LevenshteinDistance(s, t[0..lenT-1) +1,$\par 
      $LevenshteinDistance(s[0..lenS-1], t[0..lenT-1]) + cost)$ 

    \EndProcedure
  \end{algorithmic}
\end{algorithm}



The direct implementation of the \emph{levenshtein distance algorithm} has a complexity of O(mn) with m size of the first word and n size of the second word. 
Therefore it is a good utility to better understand the \emph{levenshtein distance} in general, but it is not feasible for a software that should work in production mode. 
\subsection{Optimized Levenshtein distance algorithm}
%definitions
The following definitions are based on the book \citet{automata2003}.
\begin{definition}[Non Deterministic Finite Automata]
  A non deterministic finite automata is a 5-tupel of the form $\mathcal{A} = (Q, \Sigma, q_0, \Delta, F)$. 
  \begin{itemize}
    \item Q is a finite set of the states
    \item $\Sigma$ is a finite set of input symbols
    \item $q_0 \in Q$ is the initial state
    \item $F \subset Q$ is a subset that contains the final states
    \item $\Delta$ is a relation of the form $\Delta \subset Q \times \Sigma \times Q$
  \end{itemize}
  $\mathcal{A}$ is called finite exactly when $Q$ is finite. Furthermore $\Sigma^*$ is the set of words over $\Sigma$ and $\epsilon$ is the empty word.
\end{definition}
\begin{definition}[Deterministic Finite Automata]
  $\mathcal{A}$ is deterministic if for all $p \in Q$ and all $a \in \Sigma$ exists exactly one state $q \in Q$ with $(p, a, q) \in \Delta$. In this case $\Delta$ is written as a function $\delta : Q \times \Sigma \rightarrow Q$.
\end{definition}
\begin{definition}[Path]
  A path for $\mathcal{A}$ is a series $\pi = p_0 a_1 p_1 a_2 \dots a_n p_n$, $(p_i, a_{i+1}, p_{i+1}) \in \Delta$ and $0 \leq i \leq n-1$. The length of $\pi$ is n and the label for $\beta(\pi)$ is $a_1 a_2 a_3 \dots a_n$.
\end{definition}
%\todo{$\beta$ explanation}
\begin{definition}[Path shortwriting]
  The function $\beta(\pi)$ maps a path $\pi$ to a label $\omega$.
  $\mathcal{A}: p \xrightarrow[]{\omega} q$ with $\omega \in \Sigma^*$ states, that a path $\pi$ for $\mathcal{A}$ from p to q with label $\beta(\pi) = \omega$ exists.
\end{definition}
\begin{definition}[Automata accepts a word]
  $\mathcal{A}$ accepts $\omega \in \Sigma^*$, if and only if $p \in I, q \in F$ exists with $\mathcal{A}$: $p \xrightarrow[]{\omega} q$. For $\mathcal{A}$ let $\mathcal{L}(\mathcal{A})=\{\omega \in \Sigma^*$ | $\mathcal{A}$ accepts $\omega\}$ be the language that $\mathcal{A}$ accepts.
\end{definition}

The following definitions are based on \citet{schulz2002}
\begin{definition}[Formal Levenshtein Distance]
  The levenshtein distance between two words $V, W \in \Sigma^*$ is the minimal number of edit operations (substitutions, deletions or insertions) that are needed to transform V into W.
  $d_L(V,W)$ denotes the levenshtein distance between V and W.
\end{definition}
\begin{definition}
  $\mathcal{L}_{Lev}(n, W)$, $n \in \mathbb{N}$ and $W \in \Sigma^*$ is the set that denotes all words $V \in \Sigma^*$ such that $d_L(W,V) \leq n$.
\end{definition}

\begin{definition}[Degree Levenshtein Automata]
  Let $W \in \Sigma^*$ and $n \in \mathbb{N}$. A finite state automaton A is a Levenshtein automaton of degree n for W if and only if $\mathcal{L}(A) = \mathcal{L}_{Lev}(n,W)$.
\end{definition}

An optimized version of the \emph{levenshtein distance algorithm} that uses a \emph{levenshtein automata} is described by \citet{Baeza-Yates96aunified}.
The purpose of the \emph{levenshtein automata} is to decide whether $d_L(W,V)$ is smaller than a specific $n \in \mathbb{N}$ with $V \in \Sigma^*$.
So, it is possible to decide if a word from a question is similar to a word from the \emph{STW Standard Thesaurus}, similar in the meaning it has a \emph{levenshtein distance} smaller than n.
Therefore $\Sigma$ contains the alphabet \{a,\ldots,z,A,\ldots,Z\}.
The states in Q of the \emph{levenshtein automata} denote the current position in the original word W, written as i and the current \emph{levenshtein distance} between $\omega$ and W, written as j, with $\omega$ prefix of V.
The label of such a state is $i^j$.
Thus the initial state $q_0 \in Q$ is $0^0$.
The final states $f \in F$ are all states where i equals |W| and j is smaller than n.\\
Let $\omega_{correct}$ be the correct letter after state $i^j$.
The relation $\Delta: (Q \times \Sigma \times Q)$ has the following elements.
\begin{itemize}
  \item $(i^j, \sigma, (i+1)^j)$ if $\sigma = \sigma_{correct}$ 
  \item $(i^j, \sigma, i^{(j+1)})$ if $\sigma$ is inserted after state $i^j$ and $(j+1) < n$
  \item $(i^j, \sigma, (i+1)^{(j+1)})$, if $\sigma$ is substituted by $\sigma_{correct}$ and $(j+1) < n$
  \item $(i^j, \sigma, (i+1)^{(j+1)})$, if $\omega_{correct}$ is deleted
\end{itemize}
The elements are not exclusive, therefore all of these cases can be possible after reading only one letter.
% \begin{math}
% (i^j, \sigma) \rightarrow \begin{cases}
%   (i+1)^j & \text{if correct}\\
%   (i)^{(j+1)} & \text{if insertion}\\
%   (i+1)^{(j+1)} & \text{if substitution or deletion}\\
%   empty & \text{if j is equal to n}
% \end{cases}
% \end{math}

\begin{figure}[h]
  \begin{tikzpicture}[->,auto,line width=0.2mm] 
    %0,0 row
    \node[state] (q_2) {$0^2$}; 
    \node[state] (q_1) [below =of q_2] {$0^1$}; 
    \node[state,initial] (q_0) [below =of q_1] {$0^0$}; 

    %1,0 row t
    \node[state] (q_5) [right =of q_2] {$1^2$}; 
    \node[state] (q_4) [right =of q_1] {$1^1$}; 
    \node[state] (q_3) [right =of q_0] {$1^0$}; 

    %2,0 row e
    \node[state] (q_8) [right =of q_5] {$2^2$}; 
    \node[state] (q_7) [right =of q_4] {$2^1$}; 
    \node[state] (q_6) [right =of q_3] {$2^0$};

    %3,0 row s
    \node[state] (q_11) [right =of q_8] {$3^2$}; 
    \node[state] (q_10) [right =of q_7] {$3^1$}; 
    \node[state] (q_9) [right =of q_6] {$3^0$};

    %4,0 row t
    \node[state, accepting] (q_14) [right =of q_11] {$4^2$}; 
    \node[state, accepting] (q_13) [right =of q_10] {$4^1$}; 
    \node[state, accepting] (q_12) [right =of q_9] {$4^0$};

    %path deletion 0,0
    \path[->] 
    (q_0) edge node {$\Sigma$} (q_1)
    (q_1) edge node {$\Sigma$} (q_2);
    %path 0,0 -> 1,0
    \path[->] 
    %correct path
    (q_0) edge  node {t} (q_3)
    (q_1) edge  node  {t} (q_4)
    (q_2) edge  node  {t} (q_5)

    %insertion substitution
    (q_0) edge[bend right=10]  node[above,midway] {$*$} (q_4)
    (q_0) edge[bend left=20]  node  {$\epsilon$} (q_4)


    (q_1) edge[bend right=10]  node[above,midway] {$*$} (q_5)
    (q_1) edge[bend left=20]  node  {$\epsilon$} (q_5);

    %path deletion 1,0
    \path[->] 
    (q_3) edge node {$\Sigma$} (q_4)
    (q_4) edge node {$\Sigma$} (q_5);

    %path 1,0 -> 2,0
    \path[->] 
    %correct path
    (q_3) edge  node {e} (q_6)
    (q_4) edge  node  {e} (q_7)
    (q_5) edge  node  {e} (q_8)

    %insertion substitution
    (q_3) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_7)
    (q_3) edge[bend left=20]  node  {$\epsilon$} (q_7)


    (q_4) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_8)
    (q_4) edge[bend left=20]  node  {$\epsilon$} (q_8);


    %path deletion 2,0
    \path[->] 
    (q_6) edge node {$\Sigma$} (q_7)
    (q_7) edge node {$\Sigma$} (q_8);

    %path 1,0 -> 2,0
    \path[->] 
    %correct path
    (q_6) edge  node {s} (q_9)
    (q_7) edge  node  {s} (q_10)
    (q_8) edge  node  {s} (q_11)

    %insertion substitution
    (q_6) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_10)
    (q_6) edge[bend left=20]  node  {$\epsilon$} (q_10)


    (q_7) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_11)
    (q_7) edge[bend left=20]  node  {$\epsilon$} (q_11);

    %path deletion 3,0
    \path[->] 
    (q_9) edge node {$\Sigma$} (q_10)
    (q_10) edge node {$\Sigma$} (q_11);

    %path 3,0 -> 4,0
    \path[->] 
    %correct path
    (q_9) edge  node {t} (q_12)
    (q_10) edge  node  {t} (q_13)
    (q_11) edge  node  {t} (q_14)

    %insertion substitution
    (q_9) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_13)
    (q_9) edge[bend left=20]  node  {$\epsilon$} (q_13)


    (q_10) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_14)
    (q_10) edge[bend left=20]  node  {$\epsilon$} (q_14);

    %path deletion 3,0
    \path[->] 
    (q_12) edge node {$\Sigma$} (q_13)
    (q_13) edge node {$\Sigma$} (q_14);


  \end{tikzpicture}
  \caption{A non deterministic levenshtein automata for the word \emph{test} with degree 2}
  \label{ndla}
\end{figure}
The automata in example ~\ref{ndla} is a non deterministic levenshtein automata for the word \emph{test}.
In the following description the \emph{levenshtein automata} represents the word $W in \Sigma^*$ and $\sigma \in \Sigma$ is the currently read letter.
$\Sigma$ indicates that any element from $\Sigma$ is accepted on this path.
The initial state $0^0$ is in the bottom left corner.
If $\sigma$ is a correct letter it follows the horizontal path in the automata.
A vertical path is an insertion of a letter $l \in \Sigma$ into the word W which is possible for any $\sigma$.
A diagonal path can be a deletion of a letter $l \in W$ with the empty word $\epsilon$ or a substitution of $\sigma$ for any $\sigma$.
Therefore after reading the letter 't' in the initial state $0^0$ the automata can be in five different states namely $0^1$, $1^2$, $1^1$, $2^2$ and $1^0$.
Evaluating a non deterministic levenshtein automata is computational complex due to the fact that there can be a large number of active states at the same time. 
Thus it is necessary to convert a non deterministic automata to a deterministic automata before using it to find tags.
The process of generating a deterministic automata with a non deterministic automata is called \emph{powerset construction}.

\subsubsection{Powerset Construction}
The process of creating a \emph{deterministic levenshtein automata} out of an \emph{non deterministic levenshtein automata} is based on the \emph{powerset construction} from the book \emph{Introduction to Automata Theory, Languages, and Computation} by \citet{automata2003}.
Given a \emph{non deterministic levenshtein automata} the construction of an equivalent \emph{deterministic levenshtein automata} is described below. 
\begin{itemize}
  \item Create $q_0'$ as a set with original $q_0$ and all states that are reachable with an $\epsilon$ path.
  \item $Q' \subseteq 2^Q$, thus all $q \in Q'$ are subsets of Q.
  \item $\delta(R,a) = \{q \in Q$ | $\exists r \in R$ with (r, a, q) $\in \Delta$ $\lor$ (r, $\epsilon$, q) $\in \Delta$ $\lor$ (r, $\epsilon$, p) and (p, a, q) $\in \Delta\}, R \subseteq Q$.
  \item F' includes all $q \in Q'$ that include $f \in F$
\end{itemize}
Therefore the new \emph{deterministic levenshtein automata} is (Q', $\Sigma$, $q_0'$, $\delta$, F').


\newpage
Deterministic Levenshtein automata example for the word test with max \emph{levenshtein distance} 1.
%\todo{finish automata}
\begin{figure}[h]
  \begin{tikzpicture}[->,auto,line width=0.2mm] 
    \node[state,initial, minimum size=4.5em] (0_0-1_1) {$\begin{matrix} 0^0 & 1^1 \end{matrix}$}; 
    %correct path
     \node[state] (1_0-1_1-0_1-2_1) [below left=of 0_0-1_1] {$\begin{matrix} 1^0 & 1^1\\ 0^1 & 2^1 \end{matrix}$}; 
     \node[state] (2_0-2_1-1_1-3_1) [below left=of 1_0-1_1-0_1-2_1] {$\begin{matrix} 2^0 & 2^1\\ 1^1 & 3^1 \end{matrix}$}; 
     \node[state, accepting] (3_0-3_1-2_1-4_1) [below left=of 2_0-2_1-1_1-3_1] {$\begin{matrix} 3^0 & 3^1\\ 2^1 & 4^1 \end{matrix}$}; 

     \node[state, accepting] (4_0-4_1-3_1) [below left=of 3_0-3_1-2_1-4_1] {$\begin{matrix} 4^0 & 4^1\\ 3^1 \end{matrix}$}; 

     %first not t,e
     \node[state] (0_1-1_1) [below right=of 0_0-1_1] {$\begin{matrix} 0^1 & 1^1\end{matrix}$}; 

     %first e
     \node[state] (0_1-1_1-2_1) [right=of 0_1-1_1] {$\begin{matrix} 0^1 & 1^1\\ 2^1 \end{matrix}$}; 

      %q1 edges
     \node[state] (1_1-2_1) [below right=of 1_0-1_1-0_1-2_1] {$\begin{matrix} 1^1 & 2^1 \end{matrix}$}; 
     \node[state] (1_1-2_1-3_1) [below =of 1_1-2_1] {$\begin{matrix} 1^1 & 2^1 \\ 3^1 \end{matrix}$}; 

     %elementar
     \node[state] (1_1) [below left=of 0_1-1_1-2_1] {$1^1$}; 
     \node[state] (2_1) [below right=8em of 1_1-2_1-3_1] {$2^1$}; 
     \node[state] (3_1) [below =of 2_1] {$3^1$}; 



     \node[state, accepting] (3_1-4_1) [below =of 3_0-3_1-2_1-4_1] {$\begin{matrix} 3^1 & 4^1 \end{matrix}$}; 

     \node[state] (2_1-3_1) [below =of 1_1-2_1-3_1] {$\begin{matrix} 2^1 & 3^1 \end{matrix}$}; 
     \node[state, accepting] (2_1-3_1-4_1) [below left=of 2_1-3_1] {$\begin{matrix} 2^1 & 3^1\\ 4^1 \end{matrix}$}; 
     \node[state, accepting, minimum size=4.5em] (4_1) [below =of 2_1-3_1-4_1] {$4^1$}; 
     \path[->]
     (0_0-1_1) edge node {$\neg t \wedge \neg e$} (0_1-1_1)
     (2_0-2_1-1_1-3_1) edge node {$\neg s \land \neg t$} (2_1-3_1)
     (2_0-2_1-1_1-3_1) edge node {t} (2_1-3_1-4_1)
     (0_0-1_1) edge node {e} (0_1-1_1-2_1)
     (1_0-1_1-0_1-2_1) edge node {$\neg t \wedge \neg e \wedge \neg s$} (1_1-2_1)
     (1_0-1_1-0_1-2_1) edge node {s} (1_1-2_1-3_1)
     (0_1-1_1) edge  node {t} (1_1)
     (0_1-1_1) edge  node {e} (2_1)
     (1_1) edge  node {e} (2_1)
     (2_1) edge  node {s} (3_1)
     (3_1) edge  node {t} (4_1)
     (1_1-2_1) edge  node {e} (2_1)
     (1_1-2_1) edge  node {s} (3_1)
     (3_0-3_1-2_1-4_1) edge node {$\neg$ t} (3_1-4_1)
     (3_1-4_1) edge node {t} (4_1)
     (0_0-1_1) edge  node {t} (1_0-1_1-0_1-2_1)
     (1_0-1_1-0_1-2_1) edge  node  {e} (2_0-2_1-1_1-3_1)
     (2_0-2_1-1_1-3_1) edge  node  {s} (3_0-3_1-2_1-4_1)
     (3_0-3_1-2_1-4_1) edge  node  {t} (4_0-4_1-3_1)
     (2_1-3_1-4_1) edge  node {t} (4_1)
     (2_1-3_1-4_1) edge  node {s} (3_1)
     (2_1-3_1) edge  node {s} (3_1)
     (2_1-3_1) edge  node {t} (4_1)
     (0_1-1_1-2_1) edge  node {t} (1_1)
     (0_1-1_1-2_1) edge  node {e} (2_1)
     (0_1-1_1-2_1) edge[bend left=30]  node {s} (3_1)
     (1_1-2_1-3_1) edge  node {e} (2_1)
     (1_1-2_1-3_1) edge  node {s} (3_1)
     (1_1-2_1-3_1) edge  node {t} (4_1)
     (4_0-4_1-3_1) edge  node  {*} (4_1);


  \end{tikzpicture}
  \caption{A deterministic levenshtein automata for the word \emph{test} with degree 1}
  \label{dla}

\end{figure}


% \begin{itemize}
%   \item $\Sigma$ is the complete alphabet
%   \item Each state in Q denotes for an insert word $\omega \in \Sigma^*$ the number of matching letters together with $d_L(\omega,W)$
%   \item The initial state $q_0$ is the state with insert count 0 and \emph{levenshtein distance} 0
%   \item The function $\delta$ is the known function $\delta : Q \times \Sigma \rightarrow Q$. \todo{definiere delta}
%   \item The set of final states F contains all states where the correct letter count is equal to the size of the original word W.
% \end{itemize}

Let $(Q, \Sigma, q_0, \Delta, F)$ be a \emph{non deterministic levenshtein automata} for the word \emph{test} with maximum \emph{levenshtein distance} 1 \footnote{This is the automata from figure ~\ref{ndla} without the first row}. 
Then the \emph{deterministic levenshtein automata} $DLA = (Q', \Sigma, q_0', \delta, F')$ from figure ~\ref{dla} is the output from the powerset construction.
Consequently the DLA can only have one active state at a time and accepts all words V from $\Sigma^*$ with $d_L('test', V) \leq 1$. 
This deterministic finite automata with degree $n \in \mathbb{N}$ for a word $W \in \Sigma^*$ can decide in linear time if a word $V \in \Sigma^*$ has $d_L(W,V) \leq n$. %\todo{source Lemma3}.

\begin{algorithm}
  \caption{Levenshtein Automata is in distance}\label{alg:levDistIsInDist}
  \begin{algorithmic}[1]
    \Procedure{isInDistance}{$automata: DeterministicFiniteAutomata, term: String$}
    \State $i\gets 0$
    \State $currentStates\gets (0,0)$\Comment{add the initial state}
    \While{currentStates.size > 0 AND i < term.length}
      \State $c\gets term[i].toLowerCase$\Comment{c gets the current active lower cased letter}
      \State $currentStates\gets automate.nextState(currentStates, c)$
      \State $i\gets i+1$
    \EndWhile
    \If{currentStates includes a final state}
      \State \textbf{return} true
    \Else
      \State \textbf{return} false
    \EndIf

    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The maximum distance for a given word $W \in \Sigma^*$ depends on the length n of W.
%\todo{try to find the nouns of the content cause these are the keywords of the text}
A word with length of $n\leq3$ in the \emph{Standard Thesaurus Economics} is usually an abbreviation and therefore is only used as a direct match.
A word with length of $n>3$ is used with a maximum distance of three due to the reason that most of the plural forms involve three changes (substitution, insertion and deletion) in the German language.\todo{try to find source}

%optimization generate dfa directly or use table based evaluation method

%Lemma 6 For any fixed number n, given two words W and V of length w and v respectively, it is decidable in time O(max(w, v)) if the Levenshtein distance between W and V is <= n.

%\todo{add more explanation how the levenshtein automata is integrated into the system}
To get back to the original problem this paragraph explains the application of the \emph{levenshtein distance automata} to find the right tags for a text.
The overall tagging concept is to calculate for every word from the text an automata and read all words from the \emph{STW Thesaurus for Economics} into each automata.
If a word from the \emph{STW Thesaurus for Economics} ends in a final state it is used as a tag for the text. 
A possible optimization would be to calculate once all the automata's for the complete \emph{STW Thesaurus for Economics} and to store it with an efficient data structure in a database.
Currently the \emph{STW Thesaurus for Economics} is stored in a triple store because it can easily be updated with the standard files from the website.
\todo{triple store definition}

\newpage
%why did I choose item-based and svd-based recommendations? why the combination of both
%description of item based recommendation, how do I use item based recommendations
%description of collaborative filtering, description of svd, how do I use this sort of recommendations
\section{Recommendation}
A recommendation system is a system that creates personalized item recommendations based on information about the items or the relationships between items and users.
These recommendations can be created by different types of recommendation systems that exploit different information about the users or items.
\subsection{Different types of recommendation systems}
\subsubsection{Collaborative recommendation}
Collaborative recommendations are recommendations based on similar interests of users.
So, if user A and user B are interested in similar items and user A shows interest in item I that is unknown to user B, than item I might be interesting for user B as well.
Due to the fact that this technique filters all items based on implicit collaboration of the users it is also known as \emph{collaborative filtering}.
For using the collaborative filtering approach no other information are needed than the relationship between users and items. 
Depending on the number of items in the system and the activity of the users of the system the process of collecting information about the relationship between the users and the items they are interested in might be needing some time.
Although it needs to collect initial data it is a good approach if the items that need to be recommended are unknown or additional information for the items would be hard to maintain.%\todo{read a second time more explanations needed?}
\subsubsection{Content-based recommendation}
In content-based recommendations the items are usually documents that should be recommended based on the content.
Thus, the content of the document is described by tags.
These tags can have an indicator that expresses the importance of the tag.
Therefore the documents can be filtered by the tags of the documents and ranked by the importance of the tags.
These tags can be maintained explicitly by the users of the systems or by tagging algorithms.
One advantage of content-based recommendation systems is that they do not require a large user base to achieve good recommendations for users.
A second advantage is that new items can be recommended to users immediately after the content has a description.
If the content is user generated the recommendation system can only recommend documents that fit the current context.
It has no information whether a user likes the content or not which can lead to poor recommendations.
All in all, content-based systems are a good choice if the system has to provide recommendations for quality documents.
As long as the documents have a description for the system.

\subsubsection{Knowledge-based recommendation}
The basic idea behind knowledge-based recommendation system is a system that has enough information about the items and the needs of the user and as such can recommend items based on matching the needs of the user and the features of the items.
Moreover the system has to use individual user requirements in order to create personalized recommendations. 
For example if a user would like to buy a new jacket for a summer camping trip in England the knowledge based system has to use the specific context in order to recommend a thin light rain jacket with the right size and price for the user.
These information are usually manually provided by the user and the maintainer of the system.
Furthermore not only the system needs to correctly interpret the information but the user needs to have the domain knowledge in order to provide the system with the correct information.
So, knowledge-based recommendation is a good approach if the system has to recommend items that are not frequently requested and no user history is available.
It is especially suited for applications in which items are not frequently bought such as expensive digital goods or cars. 

\subsubsection{Hybrid approaches}
All recommendation system approaches have advantages and disadvantages, therefore a combinations of the different approaches which are mentioned above could improve the user recommendations as long as the system has enough information about the items or users.

\subsubsection{Conclusion}
%\todo{improve this}
%not enough information for knowledge based system
%use tags to filter collaborative recommendations
%fall back for cold start problem
%new user / not logged in
%use top rated items for the subject
%if no items 
%use top rated items
Knowledge based systems require too much domain knowledge that is not accessible for user generated questions and answers, therefore knowledge based systems are not feasible for the system.
Collaborative recommendation systems have the \emph{cold start problem}, so they need an initial amount of user item relationship data in order to present good recommendations. 
Additionally, they have no information about the subject of the items and that is the reason why the system might recommend unapropriate items to the current context. 
Nonetheless collaborative filtering is the only approach that takes the interest of similar users into account. 
As such it is only able to recommend items that are approved by similar users. 
Moreover the content-based systems have the disadvantage that they do not make use the information whether or not a user likes a document.
Yet, they do not need to collect additional relationship information in order to recommend items.
For these reasons the described recommendation system uses a collaborative filtering technique with pre filtered content based on the tags for each item.

%%definitions Users, items, ratings, predictions
\subsection{Collaborative recommendation system}
As mentioned above a collaborative recommendation system recommends items to users based on the interest of similar users.
% -different collaborative recommendation techniques
% -user based nearest neighbor recommendations
% --Memory based approach best similarity measure pearson correlation 
% -item based
% --recommends items based on similar items
% -matrix factorization techniques
% --uses matrix factorization techniques to get latent data that is hidden in the user item matrix this data is used to create recommendations
% -probabilistic recommendation
% --Uses techniques from the probabilistic theory one of the main approaches of these techniques are to create groups of similar users, at runtime the probability for a user is calculated in which group he belongs and whether the group likes an item or not. Performance depends on the number of groups and the group size
The following definitions are based on \citet{recommender2011}
\begin{definition}[User]
  $U = \{u_1, u_2, u_3, \dots, u_n\}$ is a set with $u_i$ users from the recommendation system. With $n, i \in \mathbb{N}$ and $i \leq n$.
\end{definition}

\begin{definition}[Item]
  $I = \{i_1, i_2, i_3, \dots, i_n\}$ is a set with $i_j$ items from the recommendation system. With $n, j \in \mathbb{N}$ and $j \leq n$.
\end{definition}

\begin{definition}[Rating]
  R is an $n \times m$ matrix with $n = |I|$ and $m = |U|$. 
  Furthermore is $r_{n,m}$ a rating for item $n \in I$ and user $m \in U$ with $r_{n,m}$ entry in R and $r_{n,m} \in \{1, 2, 3, 4, 5\}$.
  If a user $k \in U$ has not rated an item $l \in I$ the entry $r_{l, k}$ remains empty.
  $\hat{I_u}$ is a set with all items $i \in I$ where $r_{i, u}$ is empty, $\tilde{I_u}$ is a set with all items i and $r_{i, u}$ is not empty.
\end{definition}

\begin{definition}[Prediction]
  A prediction is a rating $r_{i,u}$ for item $i \in I$ and user $u \in U$ with $r_{i,v}$ empty entry in $R$.
\end{definition}

\begin{definition}[Recommendation]
  Let $n \in \mathbb{N}$ and $u \in U$.
  A recommendation is a set of n predictions for a user u ordered by the values of the predictions.
\end{definition}

%There are different types of collaborative recommendation techniques.
%\todo{explain probabilistic and slope one and why you didn't choose them}

\subsubsection{Item-Based Recommendation}
The concept of item-based recommendation was introduced by \citet{sarwar2001}.
The idea behind this concept is that recommendations can be calculated based on similar items of the items that a user likes.
If $i, \in \hat{I_u}$, $u \in U$, then the prediction for i can be calculated with the similarity between i and all items $j \in \tilde{I_u}$.
There are different possible ways to calculate the similarity between two items.
However, the similarity calculation with the best performance is \emph{adjusted cosine similarity} which is an optimized form of the \emph{cosine similarity}\footnote{see \citet{sarwar2001}}
\begin{definition}[Cosine Similarity]
  With i, j $\in \mathbb{N}^n$, n $\in \mathbb{N}$.
  \begin{equation}
    cos(\overrightarrow{i}, \overrightarrow{j}) = \frac{\overrightarrow{i} \cdot \overrightarrow{j}}{||\overrightarrow{i}||_2 \cdot ||\overrightarrow{i}||_2}
  \end{equation}
\end{definition}
If $\overrightarrow{i}, \overrightarrow{j}$ are rating vectors, the individual rating behaviour of a user needs to be taken into account to get better predictions with the similarities of $\overrightarrow{i}$ and $\overrightarrow{j}$.
Due to the fact that different users have different average ratings.
This results in the \emph{adjusted cosine similarity}.
\begin{definition}[Adjusted Cosine Similarity]
  Let $i,j \in Items$ and $\overline{r_u}$ be the average rating from user u.
  The cosine similarity can be transformed to the adjusted cosine similarity by subtracting the average user rating from the current rating.
  \begin{equation}
    sim(i, j) = \frac{\sum_{u \in U}{(r_{u, i} - \overline{r_u})(r_{u, j} - \overline{r_u})}}{\sqrt{\sum_{u \in U}(r_{u,i} - \overline{r_u})^2} \sqrt{\sum_{u \in U}(r_{u,j} - \overline{r_u})^2}}
  \end{equation}
\end{definition}
Researches show that the \emph{adjusted cosine similarity} has the best performance with attention to prediction accuracy compared to all other similarity measures for item based algorithms. [\citet{sarwar2001}]
The results of the cosine similarity are between -1 and 1 with 1 meaning identical, 0 meaning indifferent and -1 meaning opposite [\citet{wikiCosineSimilarity}].
Although the results vary between -1 and 1 those items that have a \emph{cosine similarity} of $\leq 0$ are too different and thus are not used for further calculations.
The user item predictions can be generated with the similarities by using the following formula.
\begin{definition}[Item Based Prediction]
  \begin{equation}
    pred(u, p) = \frac{\sum_{i \in \tilde{I_u}}{sim(i, p) \cdot r_{u, i}}}{\sum_{i \in \tilde{I_u}}{ sim(i, p)}}
  \end{equation}
\end{definition}
Example\\
The table in figure ~\ref{itemBasedTable} represents a user item relationship.\\

\begin{figure}[h]
  \centering
  \begin{tabular}{c c c c c c}
   &Item1 & Item2 & Item3 & Item4 & Item5 \\ 
  User1 & 5 & 3 & 4 & 4 & ?\\  
  User2 & 3 & 1 & 2 & 3 & 3\\ 
  User3 & 4 & 3 & 4 & 3 & 5\\ 
  User4 & 3 & 3 & 1 & 5 & 4\\ 
  User5 & 1 & 5 & 5 & 2 & 1\\ 
  \end{tabular}
  \caption{User Item Relationship Table}
  \label{itemBasedTable}
\end{figure}

  This example calculates the item based prediction for User1 and Item5
  \begin{displaymath}
   sim(Item5,Item1) = {{3\cdot3 + 5\cdot4 + 4\cdot3 + 1\cdot1} \over {\sqrt{3^2 + 5^2 + 4^2 + 1^2} \cdot \sqrt{3^2 + 4^2 + 3^2 + 1^2}}} = 0.99
  \end{displaymath}
  sim(Item5, Item1) = 0.99\\
  sim(Item5, Item2) = 0.74\\
  sim(Item5, Item3) = 0.72\\
  sim(Item5, Item4) = 0.94\\
  With these similarities the following prediction can be calculated.
  \begin{displaymath}
    pred(User1, Item5) = {{0.99 \cdot 5 + 0.74 \cdot 3 + 0.72 \cdot 4 + 0.94 \cdot 4} \over {0.99 + 0.74 + 0.72 + 0.94}} = 4.07
  \end{displaymath}

  As a result User1 would most likely rate Item5 with 4.07.

The item similarity calculations can be calculated offline on a regular basis - every day or weekly - depending on the activeness of the users and the amount of item changes.
So, the item based technique is a good choice for websites that need fast scalable recommendations because only the item predictions are calculated on time.
Furthermore the team of \emph{Sarwar et al} found out that the system only needs a subset of all items.
According to \emph{Sarwar et al} a sample of the 25 most similar items is needed to generate good recommendations [\citet{sarwar2001}].
Moreover, it is a tested concept for instance amazon.com uses item based recommendations for their product recommendations [\citet{amazon2003}]. 
To get back to the overall concept, the item based predictions are used in order to decrease the rating sparsity of the user/item table. 
So, more information about the user interest is available before the actual recommendations can be calculated.
In real world recommendation systems the user item ratings tend to be very sparse because most users only rate few items [\citet{recommender2011}].
\subsubsection{Singular Value Decomposition}
The singular value decomposition is a matrix factorization technique that can be used to find latent factors in the rating patterns.
With these factors it is possible to find similar users and items.
The singular value decomposition was found in the late 1800 to early 1900 [\citet{historyOfSVD}].
Besides one of the main areas of application of the singular value decomposition today is information retrieval.
The basic idea behind the singular value decomposition based information retrieval is to match user queries to documents.
This is done by decomposing a term by document matrix and using the item vectors of the decomposition to find documents based on queries that are decomposed into term vectors [\citet{deerwester1990}].
\begin{definition}[Vector]
\end{definition}
\begin{definition}[Matrix]
\end{definition}
\begin{definition}[Linear Dependent, Linear Independent]
\end{definition}
\begin{definition}[Rank of a Matrix]
\end{definition}
\begin{definition}[Matrix Multiplication]
\end{definition}
\begin{definition}[Orthogonal Matrix]
\end{definition}
\begin{definition}[Eigenvalue of a Matrix]
\end{definition}

The singular value decomposition of an $m \times n$ matrix with rank r is a factorization of the form:
\begin{equation}
  SVD(M) = U \Sigma V^t
\end{equation}
U and V are orthogonal matrices with dimension $m \times r$ and $r \times n$. 
Furthermore $\Sigma$ is a rectangular diagonal matrix with dimension $r \times r$.
The diagonal values $\sigma_{i,i} \in \Sigma$ with $i \in \mathbb{N}$ have by convention the property $\sigma_{i,i} \geq \sigma_{i+1,i+1} > 0$.
The $\sigma_{i,i}$ are the none negative square roots of the eigenvalues of $AA^t$ and $A^tA$ \footnote{Due to the fact that $AA^t$ and $A^tA$ share the same eigenvalues.} [\citet{numericalLinearAlgebra}]. 
The columns of U are the corresponding eigenvectors to the eigenvalues of $AA^t$.
On the other hand are the columns of the Matrix V the corresponding eigenvectors to the eigenvalues of $A^tA$ \footnote{The eigenvalues are the squares of $\sigma_{i,i}$} [\citet{numericalLinearAlgebra}].
So, $AA^t \cdot u_i = \sigma_{i,i}^2 * u_i$.\\ %\todo{is this a reason why this spans the columns of the original matrix A?}
%\todo{U spans column space V spans row space}\\
To sum this up, the matrix U corresponds to the columns of the matrix A and the matrix V corresponds to the rows of the matrix A.
It is possible to obtain an optimal rank k approximation from matrix A, with $k \leq r$.
By setting all $\sigma_{i,i}$ with $i > k$ to zero [\citet{matrixAlgorithms}].
Thus $A_k = U_k \times \Sigma_k \times V_k^t$ yields the optimal rank k approximation.
As a result all column vectors $u_i$, with $i > k$, of matrix U will be multiplied by a zero vector from matrix $\Sigma_k$.
Due to the fact that matrix U represents the columns of matrix A and that the last rows of matrix U will be removed in order to generate the optimal rank k approximation of matrix A, it is possible to generate a good approximation of the user interests by removing the last rows of matrix U.\footnote{A user from the system is represented by a column in the matrix A}
The two dimensional matrix $U_2$ is created by removing all rows of matrix U up to the first two rows.
This matrix $U_2$ can be seen as a value table that can be represented by a graph.
Therefore, it enables a graphical presentation of the user similarities.
Furthermore the user similarities can be calculated by using the cosine similarity between the columns of $U_k$.\\
After calculating the similarities for each user, the recommendations for $user_a \in U$ are calculated.
For this task the algorithm takes all similar users $U_{sim}$ for $user_a$.\\
Afterwards it uses the top rated items from all $user_b \in U_{sim}$ that are not rated by $user_a$ $I'_{user_a, user_b}$.
$\overline{r_a}$ denotes the average rating of user a.
Finally for each item $i \in I'_{user_a, user_B}$ the prediction is calculated.

\begin{displaymath}
  pred_{a, i} = \overline{r_a} + \frac{\sum_{b \in U_{sim}}{(r_{i, b} - \overline{r_b}) * similarity_{a, b}}}{\sum_{b \in U_{sim}}{similarity_{a, b}}}
\end{displaymath}

% def getCalculateUserPredictions(userId: Int, path: Array[String]): Future[HttpResponse] = {
%   val predictions = collection.mutable.HashMap[Int, List[(Int, Int, Double)]]()
%   for(s <- SimilarUsers.byUserId(userId, 5)){
%     val (similarUserId, similarity) = s.similarityByUserId(userId).get
%     if(similarity > 0) { 
%       for(rating <- Ratings.getUnknownItemsForUserByUser(userId, similarUserId))
%       {
%         predictions += rating.itemId -> addToList(predictions.get(rating.itemId), (similarUserId, rating.rating, similarity))
%       }
%     }
%   }
%   val predictionMap = predictions.flatMap((i: (Int, List[(Int, Int, Double)])) => Map(i._1.toString->calculatePrediction(userId, i._2).toString))
%   Future.value(createHttpResponse(Json.toJson(predictionMap)))
% }

% def calculatePrediction(userAId: Int, topItems: List[(Int, Int, Double)]): Double = {
%   if(topItems.length > 1){
%     val averageRatingA = Users.get(userAId).get.averageRating
%     val numerator = topItems.map{case(userBId: Int, rating: Int, similarity: Double) => {
%       val averageRatingB = Users.get(userBId).get.averageRating
%       (rating-averageRatingB)*similarity
%     }}.sum
%     val denominator = topItems.map(_._3).sum
%     val rating = averageRatingA + numerator/denominator
%     if(rating > 0) rating else 0
%   }
%   else 0
% }

%\todo{how to calculate predictions with these tables}
\newpage
Example for a singular value based recommendation\\
\begin{displaymath}
  \begin{tabular}{c c c c c c}
     &Item1 & Item2 & Item3 & Item4 & Item5 \\ 
     User1 & 5 & 3 & 4 & 4 &  \\  
    User2 & 3 & 1 & 2 & 3 & 3\\ 
    User3 & 4 & 3 & 4 & 3 & 5\\ 
    User4 & 3 & 3 & 1 & 5 & 4\\ 
    User5 & 1 & 5 & 5 & 2 & 1\\ 
  \end{tabular} 
\end{displaymath}

The following example calculates the rating prediction for \emph{User1} and \emph{Item5}.
A singular value decomposition for a user item relationship table is created in figure ~\ref{svdexample}.
The first two rows of matrix U are used to create a value table for a graph that represents the user similarities this is displayed in figure ~\ref{svdgraph}.
The \emph{cosine similarity} is used to calculate the following similarities.
\begin{displaymath}
  %User5: 0.402286&0.716108
  %User4: 0.455479&-0.486113
  %User3: 0.535742&-0.210593
  %User2: 0.342950&-0.316949
  %User1: 0.475467&0.325691
   sim(User1,User2) = {{0.475467\cdot0.342950 + 0.325691\cdot-0.316949} \over {\sqrt{0.475467^2 + 0.325691^2} \cdot \sqrt{0.342950^2 + (-0.316949)^2}}} = 0.222322
\end{displaymath}
\begin{itemize}
  \item sim(User1, User2) = 0.222322
  \item sim(User1, User3) = 0.561072
  \item sim(User1, User4) = 0.151704
  \item sim(User1, User5) = 0.896770
\end{itemize}
The following itemization contains the average user ratings.
\begin{itemize}
  \item $\overline{r_{User2}} = 2.4$
  \item $\overline{r_{User3}} = 3.8$
  \item $\overline{r_{User4}} = 3.2$
  \item $\overline{r_{User5}} = 2.8$
\end{itemize}
  With these similarities and average ratings the following prediction can be calculated.
  $pred(User1, Item5) =$\\ $4 + \frac{(3 - 2.4) \cdot 0.222322 + (5 - 3.8) \cdot 0.561072 + (4 - 3.2) \cdot 0.151704 + (1 - 2.8) \cdot 0.896770}{0.222322 + 0.561072 + 0.151704 + 0.896770} = 3.6254$\\
  As a result User1 would most likely rate Item5 with 3.6254.
\begin{figure}[h]
\begin{math}
  \begin{tabular}{c c c c c c}
     &Item1 & Item2 & Item3 & Item4 & Item5 \\ 
     User1 & 5 & 3 & 4 & 4 &  \\  
    User2 & 3 & 1 & 2 & 3 & 3\\ 
    User3 & 4 & 3 & 4 & 3 & 5\\ 
    User4 & 3 & 3 & 1 & 5 & 4\\ 
    User5 & 1 & 5 & 5 & 2 & 1\\ 
  \end{tabular} = 

  \begin{pmatrix}
    0.475467&0.325691&0.798636&-0.053513&-0.164835\\0.342950&-0.316949&0.082532&-0.250224&0.844099\\0.535742&-0.210593&-0.362530&-0.589189&-0.435955\\0.455479&-0.486113&-0.054206&0.729352&-0.146077\\0.402286&0.716108&-0.470107&0.235423&0.221199
  \end{pmatrix} \cdot \\
  \begin{pmatrix}
    15.627834&0.0&0.0&0.0&0.0\\0.0&5.104899&0.0&0.0&0.0\\0.0&0.0&3.541202&0.0&0.0\\0.0&0.0&0.0&2.426008&0.0\\0.0&0.0&0.0&0.0&0.534013
  \end{pmatrix} \cdot \\
  \begin{pmatrix} 
    0.46825&0.432206&0.46056&0.487586&0.379564\\-0.177671&0.42127&0.572180&-0.250389&-0.633148\\0.609379&-0.316926&-0.139853&0.322858&-0.635938\\-0.392214&0.489216&-0.480126&0.571026&-0.224148\\-0.473276&-0.544015&0.458702&0.518898&-0.019831
  \end{pmatrix}
\end{math}
\caption{Singular Value Decomposition of the User Item Relationship Table}
\label{svdexample}
\end{figure}

\begin{figure}
\begin{minipage}{0.3\textwidth}
\begin{math}
    \begin{pmatrix}
    0.475467&0.325691  \\ 0.342950&-0.316949  \\ 0.535742&-0.210593 \\ 0.455479&-0.486113  \\ 0.402286&0.716108 
  \end{pmatrix} 
\end{math}
\end{minipage}
\begin{minipage}{0.7\textwidth}
\begin{tikzpicture}[scale=3.0]
 \begin{scope}[thin,black,dot/.style={fill=blue,circle,inner sep=0pt,minimum size=3pt}]
   %x-y-Koordinatensystem
%  \draw[-latex] (90:-1) --++(90:2) node[left]{$y$};
%  \draw[-latex] (0:-1) --++(0:2) node[below]{$x$};
   \coordinate (x1) at (0, 0);
   \coordinate (x2) at (1, 0);
   \coordinate (y1) at (0, -1);
   \coordinate (y2) at (0, 1);
   \draw (x1) -- (x2) node[right]{$x$};
   \draw (y1) -- (y2) node[above]{$y$};
   \node [left] at (0,0) {$0.0$};
   \node [left] at (0,-1) {$-1.0$};
   \node [left] at (0,1) {$1.0$};
   \node [below] at (1,0) {$1.0$};


   \coordinate (user1) at (0.475467, 0.325691); 
   \node[dot] at (user1);
   \node [anchor=west] at (user1) {$User1$};

   \coordinate (user2) at (0.342950, -0.316949); 
   \node[dot] at (user2);
   \node [anchor=west] at (user2) {$User2$};

   \coordinate (user3) at (0.535742, -0.210593); 
   \node[dot] at (user3);
   \node [anchor=south west] at (user3) {$User3$};

   \coordinate (user4) at (0.455479, -0.486113); 
   \node[dot] at (user4);
   \node [anchor=west] at (user4) {$User4$};

   \coordinate (user5) at (0.402286, 0.716108); 
   \node[dot] at (user5);
   \node [anchor=west] at (user5) {$User5$};

   

   
 \end{scope}
\end{tikzpicture}
\caption{Similar Users based on Singular Value Decomposition}
\label{svdgraph}
\end{minipage}
\end{figure}

\subsection{The recommendation process}
The sparsity of the user item table is decreased by using item based predictions for items that are not rated.
This improved user item table is decomposed into three matrices $U$, $\Sigma$ and $V^t$. 
The matrix U represents the user interests and is reduced by k rows in order to remove noise from the user item table and to improve the execution time of the recommendation process.%\todo{improve noise}
The cosine similarity is calculated between the columns of the matrix $U_k$ with these similarity information the recommendations are generated.
\subsection{Different Recommendation approaches}
The explained techniques that where used in the recommendation process can be used for other recommendation processes.
\subsubsection{Only Item-Based Recommendations}
\subsubsection{Only SVD-Based Recommendations}
\subsubsection{Use Item Similarities of the V Matrix}
\section{Summary}\todo{write this}
Rate items by the user activity on the webpages.
Add tags to all items, filter items by tag before using them for recommendations.
Calculate the average ratings, calculate the item similarities, calculate user predictions, calculate svd, calculate $U_k$, calculate user similarities.
Create on time recommendations.
\chapter{Implementation}
%This chapter deals with \dots
\section{Technologies}
This system combines five different concepts namely the \emph{question and answer system}, the \emph{rating system}, the \emph{tagging system}, the \emph{rating system} and the \emph{recommendation system}.
For such a variety of techniques with different requirements there was the need for different technologies.
\subsection{Programming Language}
The requirements for the programming language are that it should be object oriented for good programming code encapsulation and that the software should work on a number of different operating systems due to the reason that the development takes place on a mac operating system and the final software has to run on a linux server.
Moreover it needs to generate fast and reliable software programs as well as it should bring libraries for fast linear algebra calculations.
The linear algebra libraries are needed for the \emph{singular value decomposition}.
The different matrix calculations that one needs to have for the \emph{singular value decomposition} must be implemented the way that they are able to calculate the results as fast as possible otherwise the whole recommendation process would be too slow in order to be used on a productive system.
Such a fast execution time can only be achieved by using different tricks that utilize specific programming language features.
This implementation process would be too time consuming for a six month thesis.
For these reasons the language of choice is the scala programming language.
\subsubsection{Scala Programming Language}
The scala programming language is an object oriented and functional programming language.
Meaning that it is possible to write code with a functional programming paradigm together with an object oriented programming paradigm.
Moreover every value in scala is an object and every function is a value.
The advantage of a functional programming paradigm is that it enables a more mathematical programming approach that helps to design complex algorithm.
Additionally 
It compiles to the java byte code therefore it runs in the \emph{java runtime environment}.
Thus it is possible to use applications that are developed with the scala programming language on any system that is able to run the \emph{java runtime environment} which is almost any operating system.
Additionally an application that is developed with the scala programming language can use any java library.
So, 
\subsubsection{Javascript}
As mentioned before the javascript programming language is needed in order to create client side browser applications.
The rating systems has to track the user actions on a website in real time while the user is surfing on the website such a process is only realizable with javascript.
Javascript 
% explain scala and why scala javascript
\subsection{Databases}
\subsection{Network Communication}
\subsection{Testing}
% explain finagle
% explain triple store
% backbone js
%spec2 testing framework
%postgresql database
\section{Architecture}
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [text width = 7.5em, text badly centered, draw, ellipse,fill=red!20, node distance=4cm,
    minimum height=2em]
    
\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [cloud] (webservice) {Webservice};
    \node [cloud, right of=webservice] (recommendation) {Recommendation Service};
    \node [cloud, above right of=recommendation] (item) {Item-Based Recommendation Service};
    \node [cloud, below right of=recommendation] (svd) {SVD-Based Recommendation Service};
    \node [cloud, below of=recommendation] (tag) {Tagging Service};
    \node [cloud, below of=tag] (rating) {Rating Service};
    \node [cloud, right of=tag] (stw) {Query STW Service};
%   \node [block] (init) {initialize model};
%   \node [cloud, left of=init] (expert) {expert};
%   \node [cloud, right of=init] (system) {system};
%   \node [block, below of=init] (identify) {identify candidate models};
%   \node [block, below of=identify] (evaluate) {evaluate candidate models};
%   \node [block, left of=evaluate, node distance=3cm] (update) {update model};
%   \node [decision, below of=evaluate] (decide) {is best candidate better?};
%   \node [block, below of=decide, node distance=3cm] (stop) {stop};
    % Draw edges
%   \path [line] (init) -- (identify);
%   \path [line] (identify) -- (evaluate);
%   \path [line] (evaluate) -- (decide);
%   \path [line] (decide) -| node [near start] {yes} (update);
%   \path [line] (update) |- (identify);
%   \path [line] (decide) -- node {no}(stop);
%   \path [line,dashed] (expert) -- (init);
%   \path [line,dashed] (system) -- (init);
%   \path [line,dashed] (system) |- (evaluate);
    \path [line] (webservice) -- (recommendation);
    \path [line] (recommendation) |- (item);
    \path [line] (recommendation) |- (svd);
    \path [line] (webservice) |- (tag);
    \path [line] (webservice) |- (rating);
\end{tikzpicture}

%Service oriented architecture why?
%communication diagram
%explain diagram
\section{Services}
%what is the service for 
%how to communicate with the service
\subsection{ItemBasedService}
\subsection{SVDBasedService}
\subsection{RecommendationService}
\subsection{LevenshteinDistanceService}
\subsection{TaggerService}
service architecture
\chapter{Evaluation}
\section{Rating}
%test with diffent view timings and scroll timings according to papers
\section{Tagging}
%test 10 words 100 words 500 words 1000 words with the service
%compare original levenshtein to new levenshtein
\section{Comparison Of Different Approaches}
\subsection{Performance of the Recommendations}
\subsection{Accuracy of the Recommendations}
\subsubsection{Item-Based}
\subsubsection{Singular Value Decomposition}
\subsubsection{Hybrid Of Item-Based and Singular Value Decomposition}
\chapter{Future Work}
\section{Rating System}
\section{Tagging Service}
Direct implementation of the deterministic levenshtein automata, table based approach.
Save levenshtein automatas from all \emph{STW Standard Thesaurus Economic} words with an appropriate datastructure.
\section{Recommendation System}

\appendix

\chapter{Erster Anhang}

\chapter{Zweiter Anhang}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Literaturverzeichnis                     %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{bib}       %% statt mybib Name der eigenen .bib-Datei einsetzen 
\bibliographystyle{plainnat}

\end{document}
