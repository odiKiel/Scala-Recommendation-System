%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%% Template für Studien-, Diplom-, Bachelor- und Masterarbeiten %%
%%                 am Lehrstuhl ISE der CAU Kiel                %%
%%                                                              %%
%%                              17.10.2006                      %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
%% Stellen, an denen noch Daten eingetragen werden müssen,
%% sind mit ** gekennzeichnet.

%% Größe: A4, doppelseitig 
\documentclass[twoside,a4paper,BCOR1.0cm]{scrbook}

\usepackage{ifpdf}

\usepackage{ae,aecompl}
\usepackage[latin1]{inputenc} %% unter Linux/Unix "ansinew" evtl. durch "latin1" ersetzen
\usepackage{amsthm}
\usepackage{amsfonts}
\newtheorem{definition}{Definition}
%%\usepackage{ngerman}
%%\usepackage{url}

%% Falls PicTeX-Grafiken (z.B. aus XFig) eingebunden werden sollen
%%\usepackage{pictexwd}

%% einige mathematische Symbole (falls benötigt)
%%\usepackage{stmaryrd}
\usepackage[intlimits]{amsmath}
%%\usepackage{amssymb}

%% für listings-Umgebungen und Algorithmen
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}

%%\renewcommand{\listalgorithmname}{Listingsverzeichnis} 

%% Literatur-Verzeichnis
\usepackage{natbib}
\bibpunct{[}{]}{;}{a}{,}{,}

\ifpdf
  % für Grafiken
  \usepackage[pdftex]{graphicx}
  
  % Verweise in PDF
  \usepackage[pdftex,plainpages=false]{hyperref}
  \pdfcompresslevel=9  

  % Metadaten des Dokuments
  \hypersetup{%
    a4paper,
    pdftitle = {** Hier den Titel eintragen **},
    pdfsubject = {** Hier eine Beschreibung eintragen **},
    pdfkeywords = {** Hier Schlagwörter eintragen **},
    pdfauthor = {** Hier den Namen des Autors eintragen **},
    % pdfpagemode = None, UseThumbs, UseOutlines, FullScreen,
    % pdfstartpage = ,
    % pdfstartview = 
  }
\else
  \usepackage[plainpages=false]{hyperref}
  \usepackage{graphicx}
\fi    
\usepackage{todonotes}
\usepackage{tikz}
%\usetikzlibrary{arrows,automata,positioning}
\usetikzlibrary{%
  arrows,%
  shapes.misc,% wg. rounded rectangle
  shapes.arrows,%
  chains,%
  matrix,%
  positioning,% wg. " of "
  scopes,%
  decorations.pathmorphing,% /pgf/decoration/random steps | erste Graphik
  shadows,
  automata
}



\setlength{\parindent}{0cm}

\begin{document}
\ifpdf
  \DeclareGraphicsExtensions{.jpg, .pdf, .mps, .png}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

\renewcommand{\textfraction}{0.1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                          Titelseite                          %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{empty}

\begin{center}
{\huge \it **[Studien|Diplom|Bachelor|Master]arbeit**}

\vspace{2cm}

{\Large \bf ** Titel der Arbeit **}

\vspace{2.25cm}

%%\includegraphics[height=4cm]{CAU-Siegel}

\vspace{2.25cm}

{\large 
Christian-Albrechts-Universität zu Kiel \\
Institut für Informatik  \\
Lehrstuhl Technologie der Informationssysteme
}

\end{center}

\vspace{2cm}

\begin{tabular}{ll}
angefertigt von:             & {\bf ** eigener Name **} \\
betreuender Hochschullehrer: & ** Name des betreuenden Hochschullehrers ** \\%
%                              z.B. Prof. Dr. rer. nat. habil. Bernhard Thalheim 
%                              oder Prof. Dr. rer. nat. habil. Hans-Joachim Klein
Betreuer:                    & ** Name des Betreuers ** 
\end{tabular}

\vspace{1cm}

\begin{center}
Kiel, ** Datum der Abgabe **
\end{center}


\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                      Aufgabenstellung                        %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pagestyle{plain}
% \chapter*{Aufgabe}

% \begin{tabular}{ll}
% {\bf Name, Vorname: }               & ** Name, Vorname **                            \\
% {\bf Immatrikulations-Nr: }         & ** Immatrikulations-Nr **                      \\
% {\bf Studiengang: }                 & ** Studiengang **                              \\
%                                     &                                                \\
% {\bf betreuender Hochschullehrer: } & ** Name des Hochschullehrers **   \\
% {\bf Betreuer: }                    & ** Name des Betreuers **                       \\
% {\bf Institut: }                    & Institut für Informatik  \\
% {\bf Arbeitsgruppe: }               & Technologie der Informationssysteme            \\
%                                     &                                                \\
% {\bf Beginn am: }                   & ** Datum des Beginns **                        \\
% {\bf Einzureichen bis: }            & ** Abgabetermin **                           
% \end{tabular}

% \vspace{1cm}

% {\bf Aufgabenstellung:}

% \vspace{0.5cm}

% ** Text der Aufgabenstellung **

% \pagenumbering{roman}
% \setcounter{page}{1}
% \cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                Selbstständigkeitserklärung                   %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Selbstständigkeitserklärung}

\vspace{1.5cm}

Ich erkläre hiermit, dass ich die vorliegende Arbeit selbstständig und nur unter Verwendung der angegebenen Literatur und Hilfsmittel angefertigt habe.

\vspace{2cm}
............................................................... \\
** eigener Name **

\thispagestyle{plain}
\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Inhaltsverzeichnis                       %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Abbildungsverzeichnis                    %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listoffigures

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Tabellenverzeichnis                      %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listoftables

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                   Algorithmenverzeichnis                     %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listofalgorithms

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%              Liste der verwendeten Abkürzungen               %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abkürzungen}


\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                       Text der Arbeit                        %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abstract}
\cleardoublepage

\pagestyle{headings}
\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{Introduction}

\section{Related Work}
\section{Contributions}
\section{Overview}

%%purpose of a qa system why did I choose Askbot? 
%%how I'm getting ratings for the items
%discuss qa system, rating system, tagging system, item based, svd based, bringing it all together, display recommendations on a website
\chapter{Concepts}
The basic approach behind the system is, that it should be easy to integrate the technology into an existing system and that each described concept should work as a stand alone technology.
\section{Question and Answer Site}
A question and answer site is a website that has only one focus namely getting the right answer for a question.
Therefore a user can ask a question, this question should be precise enough and include all information that another user needs to be able to write a correct answer to the question without asking for more details.
So, it is not a discussion forum, all answers only refer to the question and the user that started the question can mark one answer as correct.
This question and answer site should open the information retrieval process on a website for the public. 
Therefore all users are able to read all questions and answers and can support domain experts by answering questions.
For each question on the site there is exactly one answer marked as correct, therefore it is possible to recommend the questions with the correct answers to users that visit a website with the same subject.
This process should increase the user interaction with the website and moreover help the user to understand the content that he is interested in.
Such question and answer sites are widely spread on the internet and there exist a couple of open source implementations that can be used for free.
Some of such open source implementations are askbot.com, discourse.org, lampcms.com and osqa.net.
They all work and almost look the same however they use different technologies and some are more mature than others.
The open source variant that is in use for the implemented system is askbot.com it is build with the django web framework and actively maintained since 2011.
\todo{why did I choose askbot some screenshots}

%explain the function and idea of a qa system, explain askbot, explain why you choosed askbot and how to integrate it.
From here on for better understanding the word item will be used instead of question and answer for an element that should be recommended.
\newpage
\section{Rating System}
In order to be able to recommend items to users it is important to understand what items a user likes.
For the purpose of such a task a rating scale ranging from 1, strongly disliked, to 5, strongly liked is used.
There are two possible forms for retrieving ratings namely implicit ratings and explicit ratings. 
Explicit ratings are those where a user is explicitly asked for his opinion on a specific item.
Implicit ratings are those where a system generates a rating according to the actions of a user.
However according to the book recommender systems an introduction \citet{recommender2011} the explicit user ratings are usually not well accepted if a direct benefit is not visible to the user. 
Moreover the explicit ratings might disturb the user experience of a website.
Adding the explicit ratings with visible benefits to an existing \emph{question answer webpage} would require too much customization, with attention to the possibility of replacing the \emph{question and answer webpage} with a different open source version or an own implementation.
Therefore it is a good approach to use implicit ratings to gather the interest of a user.
The research group of \citet{claypool2001} developed a web browser that tract implicit ratings and asked a user how they would rate the page in order to compare implicit with explicit ratings.
The implicit ratings that they measured with their web browser where:
\subsection{The time a user spends on a website}
The timer starts after the website is completely loaded and stops if the user leaves the website or closes the window.
Furthermore the timer is only active if the website is in focus in the web browser.
They found that the time a user spends on a website is a good indicator of interest.
\subsection{The time the mouse is in motion}
This was measured by timing when the mouse cursor changed its position inside the active browser window.
They found that the time a user moves the mouse cursor is proportional to the interest that a user has in the website.
However due to the fact that some users use the mouse heavily while they read the website or are looking at interesting objects, other users tend to only use the mouse in order to click on objects.
Therefore it is not possible to tell how much a user is interested in the website, it is only possible to tell which websites receive the least amount of interest.
\subsection{The number of mouse clicks}
The team of \citet{claypool2001} thought that a high number of mouse clicks would be a sign that the website has links to interesting websites or objects and that the website therefore would be valuable to the users.
However the collected data showed that the number of mouse clicks on a website aren't a good indicator for interest.
\subsection{The time a user scrolls}
The developed web browser measured the time a user scrolls a website by keys and by mouse.
Though the team of \citet{claypool2001} found that each method on its own is a poor indicator of interest, but both methods combined is a good indicator of interest.
This is explainable by the fact that some users prefer to scroll by using the mouse while others prefer the keyboard for such a task.
\begin{figure}[h]
  \centering
  \includegraphics[width=7.5cm]{image/scroll.png}
  \caption{Time spent scrolling \citet{claypool2001}}
  \label{pic:scrolltime}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=7.5cm]{image/time.png}
  \caption{Time spent on a page \citet{claypool2001}}
  \label{pic:time}
\end{figure}

\subsection{Concept}
The best sources of implicit ratings that have an accuracy of about 70\% to the explicit user ratings are the time a user spends on a web page and the amount a user scrolls on a web page according to \citet{claypool2001}.
This correlation between the implicit and explicit ratings can be explained by the fact that a user that is interested in an item takes a good look at the interesting website and reads the content that is presented on the site.
This process takes time and the user has to scroll in order to see the whole content of the website.
For the task of gathering implicit user ratings by the time that the website is in focus, the truncated mean time that all users spend on the item page is used as a benchmark.
The percentages of the two rating processes result out of the two diagrams of figure ~\ref{pic:scrolltime} and figure ~\ref{pic:time}.
\todo{improve this}
\begin{definition}[Truncated Mean]
  The truncated mean is calculated the same way as the average mean after discarding a specific percentage of the highest and lowest values.
  Let $n \in \mathbb{N}$, V be a set of sorted numbers and p be a percentage $p \geq 0$ and $p < 0.5$.
  With $k = np$ as the trimmed value, $r = n - 2k$ as the remaining values, $v_j \in V$ and $j \in \mathbb{N}$.
  \begin{displaymath}
    tm = \sum_{j=k+1}^{n-k}{v_j} \times \frac{1}{r}
  \end{displaymath}
\end{definition}
\begin{itemize}
  \item If the user spends less than 10\% of the truncated mean time on the item page it is used as a ranking of 1.
  \item If the user spends less than the truncated mean time minus 20\% on the webpage it is used as a ranking of 2.
  \item If the user spends plus minus 20\% of the truncated mean time on the item page, it is used as a ranking of 3.
  \item If the user spends longer than the truncated mean time plus 20\% on the webpage it is used as a ranking of 4.
\end{itemize}
A ranking of 5 can only be achieved if a user does a predefined user interaction on the web page.
The reason behind this choice is, that users tend to make breaks while surfing the internet.
Thus the user leaves the current browser window open, but is not in front of the computer.
Therefore it is possible, that a user is on a break and the currently active browser window might not be interesting for him.
Such a predefined user interaction that can be used as an indicator that a user likes an item for the use case of a question and answer website can be an up vote or the writing of a comment or answer. 
A similar process is chosen for determining the rating of a user by the time a user scrolls.
\begin{itemize}
  \item If the user scrolls less than 40\% of the truncated mean time on the item page it is used as a ranking of 1.
  \item If the user scrolls between 40\% and 80\% of the truncated mean time on the webpage it is used as a ranking of 2.
  \item If the user spends plus minus 20\% of the truncated mean time on the item page, it is used as a ranking of 3.
  \item If the user spends between the truncated mean time plus 20\% and 60\% on the webpage it is used as a ranking of 4.
  \item If the user scrolls longer than the truncated mean time plus 60\% it is used as a ranking of 5
\end{itemize}
Due to the fact that scrolling is an active process and the user has to be in front of the computer a rating of 5 is achievable in this process.
After calculating both ratings the average of both ratings is calculated and is used as the total rating.
\begin{displaymath}
  total rating = \frac{rating_{time} + rating_{scroll}}{2}
\end{displaymath}
\todo{add this to evaluation}The concept is build upon measurements of a field experiment of 75 students by \citet{claypool2001}, though due to the lack of time it wasn't possible to test this concept on a large user base.
If a user returns on an item site the rating that the user action results is added onto the previous rating with a maximum sum of 5.
This rating calculation results out of the observation that users tend to revisit websites that where interesting in the past and that might help the user by their current research.
However the rating can't be set to the highest rating every time, because the user might visit an uninteresting website twice without realising it.
Thus the subject of the website is interesting to the user but the content is not and therefore the low ratings of both visits result into a mediocre overall rating.
%describe the google news approach, explain the changes that where made and why.

%%source of definitions
%%why start with finite automata why create deterministic finite automata and how
\newpage
\section{Tagging}
In order to recommend the items with a matching subject on a website the system needs to be able to filter the items based on the content.
The content can be described with the use of tags, these tags are the keywords of the content.
For the context of economics the \emph{ZBW} provides the \emph{STW Thesaurus for Economics}.
The \emph{STW Thesaurus for Economics} providers vocabulary on any economic subject and it includes about 19000 terms and 6000 standardized keywords which can be used to match words from a text and provide therefore a good tagging base.
However the \emph{STW Thesaurus for Economics} only includes the basic form of the words.
Therefore a normal test for equal is not sufficient enough due to the fact that it wouldn't match on plural forms and other affix word changes.
So, the challenge for this tagging process is to find the correct words in the \emph{STW Thesaurus for Economics} even if they are in a different form then the corresponding words from the text.
One possible solution for such a task is to reduce each word from the text to its stem.
Such a task is called stemming and is usually done by using predefined rules on the words. 
A rule is usually a combination of the minimum number of letters in a word, plus the suffix that should be changed and the replacement for the suffix.
More advanced algorithms might also use rules for prefix reduction and detecting irregular changes of the stem according to \emph{Caumanns A Fast and Simple Stemming Algorithm for German Words}.
For example a predefined rule might be '3+ies' $\rightarrow$ 'y'.
So, the word \emph{libraries} would be reduced to \emph{library}.
Thus it is important that the stemming algorithm has all necessary rules for each supported language.\\
Another challenge for using the stemming algorithm is that all words in the tagging base must be in the stem form. 
Otherwise the algorithm might reduce a word to its stem that would match in it's original form.
Due to these maintenance problems the stemming algorithm is not suitable for this task.
Another possible solution for the problem is to calculate the differences between the words from the text and the words from the tagging base and use the words from the text as tags if they are in a predefined difference range.
This creates the need for a metric that indicates the difference or distance between two words.
A practical metric for such a task is the \emph{levenshtein distance}.
\subsection{Levenshtein Distance}

The \emph{levenshtein distance} calculates the minimum numbers of substitutions, insertions and deletions that are needed to change one word into another.
Example for a \emph{levenshtein distance} for the words \emph{library} and \emph{libraries}.
The algorithm has to perform two deletions and one substitution in order to create the word \emph{library} out of the word \emph{libraries}.
However if it creates the word \emph{libraries} out of the word \emph{library} it has to perform a substitution and two insertions.
Both processes result a \emph{levenshtein distance} of three.
So, the \emph{levenshtein distance} returns zero if the words are equal and adds one to the result if it has to perform a substitution an insertion or a deletion of a letter compare algorithm ~\ref{alg:levDist}.
% \todo{find better solution to move 'if'}
%   $levDist_{a,b}(i,j) = $
%   \begin{cases}
%     max(i,j) \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \text{if min(i,j) = 0} \\
%     min \begin{cases}
%         levDist_{a,b}(i-1, j)+1 \\
%         levDist_{a,b}(i, j-1)+1 & \text{else}\\
%         levDist_{a,b}(i-1, j-1) + [a_i \neq b_i] 
%       \end{cases}
%   \end{cases}\\
% This can be directly translated into a recursive algorithm. 
\begin{algorithm}
  \caption{Recursive Levenshtein Distance Algorithm}\label{alg:levDist}
  \begin{algorithmic}[1]
    \Procedure{LevenshteinDistance}{$s: String, t: String$}
    \State $lenS\gets length(s)$
    \If{lenS = 0}
      \State \textbf{return} $lenT$
    \EndIf
    \If{lenT = 0}
      \State \textbf{return} $lenS$
    \EndIf

    \If{s[lenS-1] = t[lenT-1]}\Comment{test if last characters of the strings match}
      \State $cost\gets 0$
    \Else
      \State $cost\gets 1$
    \EndIf

    \Comment{The first recursive call represents a deletion, the second represents an insertion and the third represents a substitution or a correct letter}
    \State \textbf{return} minimum of\par
    $LevenshteinDistance(s[0..lenS-1], t) +1,$\par 
    $LevenshteinDistance(s, t[0..lenT-1) +1,$\par 
      $LevenshteinDistance(s[0..lenS-1], t[0..lenT-1]) + cost)$ 

    \EndProcedure
  \end{algorithmic}
\end{algorithm}



However the direct implementation of the \emph{levenshtein distance algorithm} has a complexity of O(mn) with m size of the first word and n size of the second word. 
Therefore it is a good utility to better understand the \emph{levenshtein distance} in general, but it is not feasible for a software that should work in production mode. 
\subsection{Optimized Levenshtein distance algorithm}
%definitions
The following definitions are based on the book \citet{automata2003}.
\begin{definition}[Non Deterministic Finite Automata]
  A finite automata is a 5-tupel of the form $FA = (Q, \Sigma, q_0, \Delta, F)$. 
  \begin{itemize}
    \item Q is a finite set of the states
    \item $\Sigma$ is a finite set of input symbols
    \item $q_0 \in Q$ is the initial state
    \item $F \subset Q$ is a subset that contains the final states
    \item $\Delta$ is a relation of the form $\Delta \subset Q \times \Sigma \times Q$
  \end{itemize}
  FA is called finite exactly when $Q$ is finite. Furthermore $\Sigma^*$ is the set of words over $\Sigma$ and $\epsilon$ is the empty word.
\end{definition}
\begin{definition}[Deterministic Finite Automata]
  FA is deterministic if for all $p \in Q$ and all $a \in \Sigma$ exists exactly one state $q \in Q$ with $(p, a, q) \in \Delta$. In this case $\Delta$ is written as a function $\delta : Q \times \Sigma \rightarrow Q$.
\end{definition}
\begin{definition}[Path]
  A path for FA is a series $\pi = p_0 a_1 p_1 a_2 \dots a_n p_n$, $(p_i, a_{i+1}, p_{i+1}) \in \Delta$ and $0 \leq i \leq n-1$. The length of $\pi$ is n and the label for $\beta(\pi)$ is $a_1 a_2 a_3 \dots a_n$.
\end{definition}
\begin{definition}[Path shortwriting]
  $FA: p \xrightarrow[]{\omega} q$ with $\omega \in \Sigma^*$ states, that a path $\pi$ for FA from p to q with label $\beta(\pi) = \omega$ exists.
\end{definition}
\begin{definition}[FA accepts a word]
  FA accepts $\omega \in \Sigma^*$, if and only if $p \in I, q \in F$ exists with FA: $p \xrightarrow[]{\omega} q$. For FA let $\mathcal{L}(FA)=\{\omega \in \Sigma^*$ | FA accepts $\omega\}$ be the language that FA accepts.
\end{definition}

The following definitions are based on \citet{schulz2002}
\begin{definition}[Formal Levenshtein Distance]
  The levenshtein distance between two words $V, W \in \Sigma^*$ is the minimal number of edit operations (substitutions, deletions or insertions) that are needed to transform V into W, $d_L(V,W)$ denotes the levenshtein distance between V and W.
\end{definition}
\begin{definition}
  $\mathcal{L}_{Lev}(n, W)$, $n \in \mathbb{N}$ and $W \in \Sigma^*$ is the set that denotes all words $V \in \Sigma^*$ such that $d_L(W,V) \leq n$.
\end{definition}

\begin{definition}[Degree Levenshtein Automata]
  Let $W \in \Sigma^*$ and $n \in \mathbb{N}$. A finite state automaton A is a \emph{Levenshtein automaton} of degree n for W if and only if $\mathcal{L}(A) = \mathcal{L}_{Lev}(n,W)$.
\end{definition}

An optimized version of the \emph{levenshtein distance algorithm} that uses a \emph{levenshtein automata} is described by \citet{Baeza-Yates96aunified}.
The purpose of the \emph{levenshtein automata} is to decide whether $d_L(W,V)$ is smaller than a specific $n \in \mathbb{N}$ with $V \in \Sigma^*$.
So, it is possible to decide if a word from a question is similar to a word from the \emph{STW Standard Thesaurus}, similar in the meaning it has a \emph{levenshtein distance} smaller than n.
Therefore $\Sigma$ contains the alphabet \{a,\ldots,z,A,\ldots,Z\}.
The states in Q of the \emph{levenshtein automata} denote the current position in the original word W, written as i and the current \emph{levenshtein distance} between $\omega$ and W, written as j, with $\omega$ prefix of V.
The label of such a state is $i^j$.
Thus the initial state $q_0 \in Q$ is $0^0$.
The final states $f \in F$ are all states where i equals |W| and j is smaller than n.\\
Let $\omega_{correct}$ be the correct letter after state $i^j$.
The relation $\Delta: (Q \times \Sigma \times Q)$ has the following elements.
\begin{itemize}
  \item $(i^j, \sigma, (i+1)^j)$ if $\sigma = \sigma_{correct}$ 
  \item $(i^j, \sigma, i^{(j+1)})$ if $\sigma$ is inserted after state $i^j$ and $(j+1) < n$
  \item $(i^j, \sigma, (i+1)^{(j+1)})$, if $\sigma$ is substituted by $\sigma_{correct}$ and $(j+1) < n$
  \item $(i^j, \sigma, (i+1)^{(j+1)})$, if $\omega_{correct}$ is deleted
\end{itemize}
The elements are not exclusive, therefore all of these cases can be possible after reading only one letter.
% \begin{math}
% (i^j, \sigma) \rightarrow \begin{cases}
%   (i+1)^j & \text{if correct}\\
%   (i)^{(j+1)} & \text{if insertion}\\
%   (i+1)^{(j+1)} & \text{if substitution or deletion}\\
%   empty & \text{if j is equal to n}
% \end{cases}
% \end{math}

\begin{figure}[h]
  \begin{tikzpicture}[->,auto,line width=0.2mm] 
    %0,0 row
    \node[state] (q_2) {$0^2$}; 
    \node[state] (q_1) [below =of q_2] {$0^1$}; 
    \node[state,initial] (q_0) [below =of q_1] {$0^0$}; 

    %1,0 row t
    \node[state] (q_5) [right =of q_2] {$1^2$}; 
    \node[state] (q_4) [right =of q_1] {$1^1$}; 
    \node[state] (q_3) [right =of q_0] {$1^0$}; 

    %2,0 row e
    \node[state] (q_8) [right =of q_5] {$2^2$}; 
    \node[state] (q_7) [right =of q_4] {$2^1$}; 
    \node[state] (q_6) [right =of q_3] {$2^0$};

    %3,0 row s
    \node[state] (q_11) [right =of q_8] {$3^2$}; 
    \node[state] (q_10) [right =of q_7] {$3^1$}; 
    \node[state] (q_9) [right =of q_6] {$3^0$};

    %4,0 row t
    \node[state, accepting] (q_14) [right =of q_11] {$4^2$}; 
    \node[state, accepting] (q_13) [right =of q_10] {$4^1$}; 
    \node[state, accepting] (q_12) [right =of q_9] {$4^0$};

    %path deletion 0,0
    \path[->] 
    (q_0) edge node {$\Sigma$} (q_1)
    (q_1) edge node {$\Sigma$} (q_2);
    %path 0,0 -> 1,0
    \path[->] 
    %correct path
    (q_0) edge  node {t} (q_3)
    (q_1) edge  node  {t} (q_4)
    (q_2) edge  node  {t} (q_5)

    %insertion substitution
    (q_0) edge[bend right=10]  node[above,midway] {$*$} (q_4)
    (q_0) edge[bend left=20]  node  {$\epsilon$} (q_4)


    (q_1) edge[bend right=10]  node[above,midway] {$*$} (q_5)
    (q_1) edge[bend left=20]  node  {$\epsilon$} (q_5);

    %path deletion 1,0
    \path[->] 
    (q_3) edge node {$\Sigma$} (q_4)
    (q_4) edge node {$\Sigma$} (q_5);

    %path 1,0 -> 2,0
    \path[->] 
    %correct path
    (q_3) edge  node {e} (q_6)
    (q_4) edge  node  {e} (q_7)
    (q_5) edge  node  {e} (q_8)

    %insertion substitution
    (q_3) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_7)
    (q_3) edge[bend left=20]  node  {$\epsilon$} (q_7)


    (q_4) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_8)
    (q_4) edge[bend left=20]  node  {$\epsilon$} (q_8);


    %path deletion 2,0
    \path[->] 
    (q_6) edge node {$\Sigma$} (q_7)
    (q_7) edge node {$\Sigma$} (q_8);

    %path 1,0 -> 2,0
    \path[->] 
    %correct path
    (q_6) edge  node {s} (q_9)
    (q_7) edge  node  {s} (q_10)
    (q_8) edge  node  {s} (q_11)

    %insertion substitution
    (q_6) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_10)
    (q_6) edge[bend left=20]  node  {$\epsilon$} (q_10)


    (q_7) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_11)
    (q_7) edge[bend left=20]  node  {$\epsilon$} (q_11);

    %path deletion 3,0
    \path[->] 
    (q_9) edge node {$\Sigma$} (q_10)
    (q_10) edge node {$\Sigma$} (q_11);

    %path 3,0 -> 4,0
    \path[->] 
    %correct path
    (q_9) edge  node {t} (q_12)
    (q_10) edge  node  {t} (q_13)
    (q_11) edge  node  {t} (q_14)

    %insertion substitution
    (q_9) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_13)
    (q_9) edge[bend left=20]  node  {$\epsilon$} (q_13)


    (q_10) edge[bend right=10]  node[above,midway] {$\Sigma$} (q_14)
    (q_10) edge[bend left=20]  node  {$\epsilon$} (q_14);

    %path deletion 3,0
    \path[->] 
    (q_12) edge node {$\Sigma$} (q_13)
    (q_13) edge node {$\Sigma$} (q_14);


  \end{tikzpicture}
  \caption{A non deterministic levenshtein automata for the word \emph{test} with degree 2}
  \label{ndla}
\end{figure}
The automata in example ~\ref{ndla} is a non deterministic levenshtein automata for the word \emph{test}.
In the following description the \emph{levenshtein automata} represents the word $W in \Sigma^*$ and $\sigma \in \Sigma$ is the currently read letter.
$\Sigma$ indicates that any element from $\Sigma$ is accepted on this path.
The initial state $0^0$ is in the bottom left corner.
If $\sigma$ is a correct letter it follows the horizontal path in the automata.
A vertical path is an insertion of a letter $l \in \Sigma$ into the word W which is possible for any $\sigma$.
A diagonal path can be a deletion of a letter $l \in W$ with the empty word $\epsilon$ or a substitution of $\sigma$ for any $\sigma$.
Therefore after reading the letter 't' in the initial state $0^0$ the automata can be in five different states namely $0^1$, $1^2$, $1^1$, $2^2$ and $1^0$.
Evaluating a non deterministic levenshtein automata is computational complex due to the fact that there can be a large number of active states at the same time. 
Thus it is necessary to convert a non deterministic automata to a deterministic automata before using it to find tags.
The process of generating a deterministic automata with a non deterministic automata is called \emph{powerset construction}.

\subsubsection{Powerset Construction}
\todo{add source book Introduction to Automata Theory, Languages and Computation by Hopcroft, Motwani }
Given a \emph{non deterministic levenshtein automata} the construction of an equivalent \emph{deterministic levenshtein automata}: 
\begin{itemize}
  \item create $q_0'$ as a set with original $q_0$ and all states that are reachable with an $\epsilon$ path.
  \item $Q' \subseteq 2^Q$, thus all $q \in Q'$ are subsets of Q.
  \item $\delta(R,a) = \{q \in Q$ | $\exists r \in R$ with (r, a, q) $\in \Delta$ $\lor$ (r, $\epsilon$, q) $\in \Delta$ $\lor$ (r, $\epsilon$, p) and (p, a, q) $\in \Delta\}, R \subseteq Q$.
  \item F' includes all $q \in Q'$ that include $f \in F$
\end{itemize}
Therefore the new \emph{deterministic levenshtein automata} is (Q', $\Sigma$, $q_0'$, $\delta$, F').


\newpage
Deterministic Levenshtein automata example for the word test with max \emph{levenshtein distance} 1.
\todo{finish automata}
\begin{figure}[h]
  \begin{tikzpicture}[->,auto,line width=0.2mm] 
    \node[state,initial, minimum size=4.5em] (0_0-1_1) {$\begin{matrix} 0^0 & 1^1 \end{matrix}$}; 
    %correct path
     \node[state] (1_0-1_1-0_1-2_1) [below left=of 0_0-1_1] {$\begin{matrix} 1^0 & 1^1\\ 0^1 & 2^1 \end{matrix}$}; 
     \node[state] (2_0-2_1-1_1-3_1) [below left=of 1_0-1_1-0_1-2_1] {$\begin{matrix} 2^0 & 2^1\\ 1^1 & 3^1 \end{matrix}$}; 
     \node[state, accepting] (3_0-3_1-2_1-4_1) [below left=of 2_0-2_1-1_1-3_1] {$\begin{matrix} 3^0 & 3^1\\ 2^1 & 4^1 \end{matrix}$}; 

     \node[state, accepting] (4_0-4_1-3_1) [below left=of 3_0-3_1-2_1-4_1] {$\begin{matrix} 4^0 & 4^1\\ 3^1 \end{matrix}$}; 

     %first not t,e
     \node[state] (0_1-1_1) [below right=of 0_0-1_1] {$\begin{matrix} 0^1 & 1^1\end{matrix}$}; 

     %first e
     \node[state] (0_1-1_1-2_1) [right=of 0_1-1_1] {$\begin{matrix} 0^1 & 1^1\\ 2^1 \end{matrix}$}; 

      %q1 edges
     \node[state] (1_1-2_1) [below right=of 1_0-1_1-0_1-2_1] {$\begin{matrix} 1^1 & 2^1 \end{matrix}$}; 
     \node[state] (1_1-2_1-3_1) [below =of 1_1-2_1] {$\begin{matrix} 1^1 & 2^1 \\ 3^1 \end{matrix}$}; 

     %elementar
     \node[state] (1_1) [below left=of 0_1-1_1-2_1] {$1^1$}; 
     \node[state] (2_1) [below right=8em of 1_1-2_1-3_1] {$2^1$}; 
     \node[state] (3_1) [below =of 2_1] {$3^1$}; 



     \node[state, accepting] (3_1-4_1) [below =of 3_0-3_1-2_1-4_1] {$\begin{matrix} 3^1 & 4^1 \end{matrix}$}; 

     \node[state] (2_1-3_1) [below =of 1_1-2_1-3_1] {$\begin{matrix} 2^1 & 3^1 \end{matrix}$}; 
     \node[state, accepting] (2_1-3_1-4_1) [below left=of 2_1-3_1] {$\begin{matrix} 2^1 & 3^1\\ 4^1 \end{matrix}$}; 
     \node[state, accepting, minimum size=4.5em] (4_1) [below =of 2_1-3_1-4_1] {$4^1$}; 
     \path[->]
     (0_0-1_1) edge node {$\neg t \wedge \neg e$} (0_1-1_1)
     (2_0-2_1-1_1-3_1) edge node {$\neg s \land \neg t$} (2_1-3_1)
     (2_0-2_1-1_1-3_1) edge node {t} (2_1-3_1-4_1)
     (0_0-1_1) edge node {e} (0_1-1_1-2_1)
     (1_0-1_1-0_1-2_1) edge node {$\neg t \wedge \neg e \wedge \neg s$} (1_1-2_1)
     (1_0-1_1-0_1-2_1) edge node {s} (1_1-2_1-3_1)
     (0_1-1_1) edge  node {t} (1_1)
     (0_1-1_1) edge  node {e} (2_1)
     (1_1) edge  node {e} (2_1)
     (2_1) edge  node {s} (3_1)
     (3_1) edge  node {t} (4_1)
     (1_1-2_1) edge  node {e} (2_1)
     (1_1-2_1) edge  node {s} (3_1)
     (3_0-3_1-2_1-4_1) edge node {$\neg$ t} (3_1-4_1)
     (3_1-4_1) edge node {t} (4_1)
     (0_0-1_1) edge  node {t} (1_0-1_1-0_1-2_1)
     (1_0-1_1-0_1-2_1) edge  node  {e} (2_0-2_1-1_1-3_1)
     (2_0-2_1-1_1-3_1) edge  node  {s} (3_0-3_1-2_1-4_1)
     (3_0-3_1-2_1-4_1) edge  node  {t} (4_0-4_1-3_1)
     (2_1-3_1-4_1) edge  node {t} (4_1)
     (2_1-3_1-4_1) edge  node {s} (3_1)
     (2_1-3_1) edge  node {s} (3_1)
     (2_1-3_1) edge  node {t} (4_1)
     (0_1-1_1-2_1) edge  node {t} (1_1)
     (0_1-1_1-2_1) edge  node {e} (2_1)
     (0_1-1_1-2_1) edge[bend left=30]  node {s} (3_1)
     (1_1-2_1-3_1) edge  node {e} (2_1)
     (1_1-2_1-3_1) edge  node {s} (3_1)
     (1_1-2_1-3_1) edge  node {t} (4_1)
     (4_0-4_1-3_1) edge  node  {*} (4_1);


  \end{tikzpicture}
  \caption{A deterministic levenshtein automata for the word \emph{test} with degree 1}
  \label{dla}

\end{figure}


% \begin{itemize}
%   \item $\Sigma$ is the complete alphabet
%   \item Each state in Q denotes for an insert word $\omega \in \Sigma^*$ the number of matching letters together with $d_L(\omega,W)$
%   \item The initial state $q_0$ is the state with insert count 0 and \emph{levenshtein distance} 0
%   \item The function $\delta$ is the known function $\delta : Q \times \Sigma \rightarrow Q$. \todo{definiere delta}
%   \item The set of final states F contains all states where the correct letter count is equal to the size of the original word W.
% \end{itemize}

Let $NDLA = (Q, \Sigma, q_0, \Delta, F)$ be a \emph{non deterministic levenshtein automata} for the word \emph{test} with max \emph{levenshtein distance} 1 \footnote{Therefore the automata from figure ~\ref{ndla} without the first row} then the \emph{deterministic levenshtein automata} $DLA = (Q', \Sigma, q_0', \delta, F')$ from figure ~\ref{dla} is the output from the powerset construction.
Therefore DLA can only have one active state at a time and accepts all words V from $\Sigma^*$ with $d_L('test', V) \leq 1$. 
This deterministic finite automata with degree $n \in \mathbb{N}$ for a word $W \in \Sigma^*$ can decide in linear time if for a word $V \in \Sigma^*$ $d_L(W,V) \leq n$ source Lemma3.

\begin{algorithm}
  \caption{Levenshtein Automata is in distance}\label{alg:levDistIsInDist}
  \begin{algorithmic}[1]
    \Procedure{isInDistance}{$automata: DeterministicFiniteAutomata, term: String$}
    \State $i\gets 0$
    \State $currentStates\gets (0,0)$\Comment{add the initial state}
    \While{currentStates.size > 0 AND i < term.length}
      \State $c\gets term[i].toLowerCase$\Comment{c gets the current active lower cased letter}
      \State $currentStates\gets automate.nextState(currentStates, c)$
      \State $i\gets i+1$
    \EndWhile
    \If{currentStates includes a final state}
      \State \textbf{return} true
    \Else
      \State \textbf{return} false
    \EndIf

    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\todo{describe word size maximum correction count correlation.}
The maximum distance for a given word $W \in \Sigma^*$ depends on the length n of W.
A word with length of $n\leq3$ in the \emph{Standard Thesaurus Economics} is usually an abbreviation and therefore is only used as a direct match.
A word with length of $n>3$ is used with a maximum distance of three due to the reason that most of the plural postfix endings have a maximum length of three in the German language.\todo{try to find source}

%optimization generate dfa directly or use table based evaluation method

%Lemma 6 For any fixed number n, given two words W and V of length w and v respectively, it is decidable in time O(max(w, v)) if the Levenshtein distance between W and V is <= n.

\todo{add more explanation how the levenshtein automata is integrated into the system}
To get back to the original problem of finding the right tags for a text.
The overall tagging concept is to calculate for every word from the text an automata and read all words from the \emph{STW Thesaurus for Economics} into each automata.
If a word from the \emph{STW Thesaurus for Economics} ends in a final state it is used as a tag for the text. 
A possible optimization would be to calculate once all the automata's for the complete \emph{STW Thesaurus for Economics} and to store it with an efficient data structure in a database.
Currently the \emph{STW Thesaurus for Economics} is stored in a triple store, because it can easily be updated with the standard files from the website.

\newpage
%why did I choose item-based and svd-based recommendations? why the combination of both
%description of item based recommendation, how do I use item based recommendations
%description of collaborative filtering, description of svd, how do I use this sort of recommendations
\section{Recommendation}

A recommendation system creates personalized item recommendations for users. \todo{more general stuff}
These recommendations can be created by different types of recommendation system, that exploit different information about the users or items.
\subsection{Different types of recommendation systems}
\subsubsection{Collaborative recommendation}
Collaborative recommendations are recommendations based on similar interests of users. So, if user A and user B are interested in similar items and user A shows interest in item I that is unknown to user B, than item I might be interesting for user B as well. Due to the fact that this technique filters all items based on implicit collaboration of the users it is also known as \emph{collaborative filtering}.
For using the collaborative filtering approach no other information are needed than the relationship between users and items. 
However the relationship information between the users and the items might take some time to gather depending on the number of items in the system and the activity of the users of the system.
Therefore it is a good approach if the items that needs to be recommended are unknown or additional information for the items would be hard to maintain.
\subsubsection{Content-based recommendation}
In content-based recommendations the items are usually documents that should be recommended based on the content.
Thus, the content of the document is described by tags that can have an importance indicator.
Therefore the documents can be filtered by the tags of the documents and ranked by the importance of the tags.
These tags can be maintained explicitly by the users of the systems or by tagging algorithms.
One advantage of content-based recommendation systems is that it doesn't require a large user base to achieve good recommendations for users.
A second advantage is that new items can be recommended to users immediately after the content has a description.
However if the content is user generated the recommendation system can only recommend documents that fit the current context. It has no information if a user likes the content or not which can lead to poor recommendations.
All in all, content-based systems are a good choice if the system has to provide recommendations for quality documents.
As long as the documents have a description for the system.

\subsubsection{Knowledge-based recommendation}
The basic idea behind knowledge-based recommendation system is, that if a system has enough information about the items and the needs of the user, it can recommend items based on matching the needs of the user and the features of the items.
Moreover the system has to use individual user requirements in order to create personalized recommendations. 
For example if a user would like to buy a new jacket for a summer camping trip in england. The knowledge based system has to use the specific context in order to recommend a thin light rain jacket with the right size and price for the user.
These information are usually manually provided by the user and the maintainer of the system.
Furthermore not only the system needs to correctly interpret the information, the user needs to have the domain knowledge in order to provide the system with the correct information.
So, knowledge-based recommendation is a good approach if the system has to recommend items that aren't frequently requested and therefore no user history is available. Such as expensive digital goods, cars and so on.

\subsubsection{Hybrid approaches}
All recommendation system approaches have advantages and disadvantages, therefore it is a good approach to combine different techniques to improve the user recommendations, if the system has enough information about the items or users.

\subsubsection{Conclusion}
\todo{improve this}
%not enough information for knowledge based system
%use tags to filter collaborative recommendations
%fall back for cold start problem
%new user / not logged in
%use top rated items for the subject
%if no items 
%use top rated items
Knowledge based systems require too much domain knowledge that is not accessible for user generated questions and answers, therefore knowledge based systems aren't feasible for the system.
Collaborative recommendation systems have the \emph{cold start problem}, so they need an initial amount of user item relationship data in order to present good recommendations. 
Furthermore they have no information about the subject of the items therefore they might recommend unapropriate items to the current context. 
Nonetheless collaborative filtering is the only approach that takes the interest of similar users into account. 
Therefore it is able to only recommend items that are \emph{approved}, in hindsight that similar users liked the items.
Moreover the content-based systems have the disadvantage that they don't use the information whether or not a user likes a document.
However they do not have the cold start problem.

For these reasons the described recommendation system uses a collaborative filtering technique with pre filtered content, based on the tags for each item.

%%definitions Users, items, ratings, predictions
\subsection{Collaborative recommendation techniques}
There are different types of collaborative recommendation techniques.
\todo{explain probabilistic and slope one and why you didn't choose them}
The following definitions are based on \citet{recommender2011}
\begin{definition}[User]
  $U = \{u_1, u_2, u_3, \dots, u_n\}$ is a set with $u_i$ users from the recommendation system. With $n, i \in \mathbb{N}$ and $i \leq n$.
\end{definition}

\begin{definition}[Item]
  $I = \{i_1, i_2, i_3, \dots, i_n\}$ is a set with $i_j$ items from the recommendation system. With $n, j \in \mathbb{N}$ and $j \leq n$.
\end{definition}

\begin{definition}[Rating]
  R is an $n \times m$ matrix with $n = |I|$ and $m = |U|$. Furthermore is $r_{n,m}$ a rating for item $n \in I$ and user $m \in U$ with $r_{n,m}$ entry in R and $r_{n,m} \in \{1, 2, 3, 4, 5\}$. If a user $k \in U$ hasn't rated an item $l \in I$ yet the entry $r_{l, k}$ remains empty.
  $\hat{I_u}$ is a set with all items $i \in I$ where $r_{i, u}$ is empty, $\tilde{I_u}$ is a set with all items i and $r_{i, u}$ is not empty.
\end{definition}

\begin{definition}[Prediction]
  A prediction is a rating $r_{i,u}$ for item $i \in I$ and user $u \in U$ with $r_{i,v}$ empty entry in $R$.
\end{definition}

\begin{definition}[Recommendation]
  Let $n \in \mathbb{N}$ and $u \in U$.
  A recommendation is a set of n predictions for a user u ordered by the values of the predictions.
\end{definition}


\subsubsection{Item-Based Recommendation}
The concepts of item-based recommendations was introduced in 2001 by Sarwar et al \emph{Item-Based Collaborative Filtering Recommendation Algorithms}.
The idea behind this concept is that recommendations can be calculated based on similar items of the items that a user likes. If $i, \in \hat{I_u}$, $u \in U$, then the prediction for i can be calculated with the similarity between i and all items $j \in \tilde{I_u}$.
There are different possible ways to calculate the similarity between two items. However the similarity calculation with the best performance is \emph{adjusted cosine similarity} which is an optimized form of the \emph{cosine similarity}. (see Sarwar et al)
\begin{definition}[Cosinus Similarity]
  With i, j $\in \mathbb{N}^n$, n $\in \mathbb{N}$.
  \begin{equation}
    cos(\overrightarrow{i}, \overrightarrow{j}) = \frac{\overrightarrow{i} \cdot \overrightarrow{j}}{||\overrightarrow{i}||_2 \cdot ||\overrightarrow{i}||_2}
  \end{equation}
\end{definition}
If $\overrightarrow{i}, \overrightarrow{j}$ are rating vectors, the individual rating behaviour of a user needs to be taken into account to get better predictions with the similarities of $\overrightarrow{i}$ and $\overrightarrow{j}$. Due to the fact that different users have different average ratings. This results into the \emph{adjusted cosine similarity}.
\begin{definition}[Adjusted Cosine Similarity]
  With $i,j \in Items$ and $\overline{r_u}$ average rating from user u. The cosine similarity can be transformed to the adjusted cosine similarity by subtracting the average user rating from the current rating.
  \begin{equation}
    sim(i, j) = \frac{\sum_{u \in U}{(r_{u, i} - \overline{r_u})(r_{u, j} - \overline{r_u})}}{\sqrt{\sum_{u \in U}(r_{u,i} - \overline{r_u})^2} \sqrt{\sum_{u \in U}(r_{u,j} - \overline{r_u})^2}}
  \end{equation}
\end{definition}
Researches show that the \emph{adjusted cosine similarity} has the best performance with focus on prediction accuracy from all other similarity measures for item based algorithms \todo{source Sarwar et al 2001}.
The results of the cosine similarity are between -1 and 1, with 1 meaning identical 0 meaning indifferent and -1 \todo{find source}.
However items that have a cosine similarity of $\leq 0$ are too different and aren't used for further calculations.
The user item predictions can be generated with the similarities by using the following formula.
\begin{definition}[Item Based Prediction]
  \begin{equation}
    pred(u, p) = \frac{\sum_{i \in \tilde{I_u}}{sim(i, p) * r_{u, i}}}{\sum_{i \in \tilde{I_u}}{ sim(i, p)}}
  \end{equation}
\end{definition}
Example\\
The table in figure ~\ref{itemBasedTable} represents a user item relationship.\\

\begin{figure}[h]
  \centering
  \begin{tabular}{c c c c c c}
   &Item1 & Item2 & Item3 & Item4 & Item5 \\ 
  User1 & 5 & 3 & 4 & 4 & ?\\  
  User2 & 3 & 1 & 2 & 3 & 3\\ 
  User3 & 4 & 3 & 4 & 3 & 5\\ 
  User4 & 3 & 3 & 1 & 5 & 4\\ 
  User5 & 1 & 5 & 5 & 2 & 1\\ 
  \end{tabular}
  \caption{User Item Relationship Table}
  \label{itemBasedTable}
\end{figure}

  This example calculates the item based prediction for User1 and Item5
  \begin{displaymath}
   sim(Item5,Item1) = {{3\cdot3 + 5\cdot4 + 4\cdot3 + 1\cdot1} \over {\sqrt{3^2 + 5^2 + 4^2 + 1^2} \cdot \sqrt{3^2 + 4^2 + 3^2 + 1^2}}} = 0.99
  \end{displaymath}
  sim(Item5, Item1) = 0.99\\
  sim(Item5, Item2) = 0.74\\
  sim(Item5, Item3) = 0.72\\
  sim(Item5, Item4) = 0.94\\
  With these similarities the prediction can be calculated:
  \begin{displaymath}
    pred(User1, I5) = {{0.99 \cdot 5 + 0.74 \cdot 3 + 0.72 \cdot 4 + 0.94 \cdot 4} \over {0.99 + 0.74 + 0.72 + 0.94}} = 4.07
  \end{displaymath}

  Therefore User1 would most likely rate Item5 with 4.07.

The item similarity calculations can be calculated offline on a regular basis, every day or week depending on the activeness of the users and the amount of item changes.
So, the item based technique is a good choice for websites that need fast scalable recommendations, because only the item predictions are calculated on time.
Furthermore the team of \emph{Sarwar et al} found that the system only needs a subset of all items, a sample of the 25 most similar items are needed to generate good recommendations \citet{sarwar2001}.
Moreover it is a tested concept, amazon.com uses item based recommendations for their product recommendations \citet{amazon2003}. 
To get back to the overall concept item based predictions are used in order to decrease the scarcity of the rating matrix. 
So, more information about the user interest is available before the actual recommendations can be calculated.
\begin{definition}[Scarcity]
  Scarcity is \ldots It should be minimized in order to \ldots \todo{write this}
\end{definition}
\subsubsection{Singular Value Decomposition}
The singular value decomposition is a matrix factorization technique that can be used to find latent factors in the rating patterns, with these factors it is possible to find similar users and items.
The singular value decomposition was invented by \todo{find source}, one of the main \todo{anwendungsgebiete} applications of the svd is information retrieval.
The basic idea behind the svd based information retrieval is to match user queries to documents by decomposing a term by document matrix and using the item vectors of the decomposition to find documents based on queries that are decomposed into term vectors \citet{deerwester1990}.
\begin{definition}[Vector]
\end{definition}
\begin{definition}[Matrix]
\end{definition}
\begin{definition}[Linear Dependent, Linear Independent]
\end{definition}
\begin{definition}[Rank of a Matrix]
\end{definition}
\begin{definition}[Matrix Multiplication]
\end{definition}
\begin{definition}[Orthogonal Matrix]
\todo{add definition of orthogonal vector and orthogonal matrix and eigenvector / eigenvalue}
\end{definition}
\begin{definition}[Eigenvalue of a Matrix]
\todo{add definition of orthogonal vector and orthogonal matrix and eigenvector / eigenvalue}
\end{definition}
\todo{add source for this subsection: Incremental Singular Value Decomposition Algorithms for Highly Scalable Recommender Systems by Sarwar et al}

The singular value decomposition of an $m \times n$ matrix with rank r is a factorization of the form:
\begin{equation}
  SVD(M) = U \Sigma V^t
\end{equation}
U and V are orthogonal matrices with dimension $m \times r$ and $r \times n$. 
Furthermore is $\Sigma$ a rectangular diagonal matrix with dimension $r \times r$.
The diagonal values $\sigma_{i,i} \in \Sigma$ with $i \in \mathbb{N}$ have by convention the property $\sigma_{i,i} \geq \sigma_{i+1,i+1} > 0$.
Furthermore are the $\sigma_{i,i}$ the none negative square roots of the eigenvalues of $AA^t$ and $A^tA$ \footnote{Due to the fact that $AA^t$ and $A^tA$ share the same eigenvalues.}. \todo{source Numerical Lineal Algebra Allaire and Kaber Springer Verlag}
The columns of U are the corresponding eigenvectors to the eigenvalues of $AA^t$.
On the other hand are the columns of the Matrix V the corresponding eigenvectors to the eigenvalues of $A^tA$ \footnote{The eigenvalues are the squares of $\sigma_{i,i}$}\todo{source Numerical Linear Algebra}.
So, $AA^t * u_i = \sigma_{i,i}^2 * u_i$. \todo{is this a reason why this spans the columns of the original matrix A?}
\todo{U spans column space V spans row space}\\
To sum up, the matrix U corresponds to the columns of the matrix A and the matrix V corresponds to the rows of the matrix A.
Furthermore it is possible to obtain an optimal rank k approximation from matrix A, with $k \leq r$.
By setting all $\sigma_{i,i}$, with $i > k$ to zero.\todo{add source: Matrix algorithms / Vol. 1 / Basic decompositions / Gilbert W. Stewart. - 1998}
Thus $A_k = U \times \Sigma \times V^t$ yields the optimal rank k approximation.
Therefore all column vectors $u_i$, with $i > k$, of matrix U will be multiplied by a zero vector from matrix $\Sigma$.
Due to the fact that matrix U represents the columns of matrix A and that the last rows of matrix U will be removed in order to generate the optimal rank k approximation of matrix A, it is possible to generate a good approximation of the user interests.\footnote{A user from the system is represented by a column in the matrix A}
For example by removing all rows of matrix U up to the first two rows $U_2$ yields a two dimensional table that is drawable onto a graph.
The user similarities can be calculated by using the cosine similarity between the columns of $U_k$.\\
The recommendations for $user_1$ are calculated by using the top rated items, that are unknown to $user_1$, of the most similar users compare algorithm. \todo{improve this}
% def getCalculateUserPredictions(userId: Int, path: Array[String]): Future[HttpResponse] = {
%   val predictions = collection.mutable.HashMap[Int, List[(Int, Int, Double)]]()
%   for(s <- SimilarUsers.byUserId(userId, 5)){
%     val (similarUserId, similarity) = s.similarityByUserId(userId).get
%     if(similarity > 0) { 
%       for(rating <- Ratings.getUnknownItemsForUserByUser(userId, similarUserId))
%       {
%         predictions += rating.itemId -> addToList(predictions.get(rating.itemId), (similarUserId, rating.rating, similarity))
%       }
%     }
%   }
%   val predictionMap = predictions.flatMap((i: (Int, List[(Int, Int, Double)])) => Map(i._1.toString->calculatePrediction(userId, i._2).toString))
%   Future.value(createHttpResponse(Json.toJson(predictionMap)))
% }

% def calculatePrediction(userAId: Int, topItems: List[(Int, Int, Double)]): Double = {
%   if(topItems.length > 1){
%     val averageRatingA = Users.get(userAId).get.averageRating
%     val numerator = topItems.map{case(userBId: Int, rating: Int, similarity: Double) => {
%       val averageRatingB = Users.get(userBId).get.averageRating
%       (rating-averageRatingB)*similarity
%     }}.sum
%     val denominator = topItems.map(_._3).sum
%     val rating = averageRatingA + numerator/denominator
%     if(rating > 0) rating else 0
%   }
%   else 0
% }

\todo{how to calculate predictions with these tables}
Example\\
A singular value decomposition for a user item relationship table is created in figure ~\ref{svdexample}.
The first two rows of matrix U are used to create a value table for a graph that represents the user similarities compare figure ~\ref{svdgraph}.
The angle between lines from the graph origin to the users are used to calculate the similarities.
\begin{figure}[h]
\begin{math}
  \begin{tabular}{c c c c c c}
     &Item1 & Item2 & Item3 & Item4 & Item5 \\ 
     User1 & 5 & 3 & 4 & 4 & 4\\  
    User2 & 3 & 1 & 2 & 3 & 3\\ 
    User3 & 4 & 3 & 4 & 3 & 5\\ 
    User4 & 3 & 3 & 1 & 5 & 4\\ 
    User5 & 1 & 5 & 5 & 2 & 1\\ 
  \end{tabular} = 

  \begin{pmatrix}
    0.544178 & 0.0875457 & 0.303701 & -0.598262 & -0.496039 \\ 0.330582 & 0.270665 & 0.155794 & -0.281254 & 0.845033 \\ 0.517601 & 0.04377 & 0.429477 & 0.737011 & -0.0503875 \\ 0.438285 & 0.373564 & -0.800903 & 0.129864 & -0.100232 \\ 0.366854 & -0.881822 & -0.239996 & -0.0541261 & 0.165165
  \end{pmatrix} \cdot \\
  \begin{pmatrix}
    16.499 & 0 & 0 & 0 & 0 \\ 0 & 4.93905 & 0 & 0 & 0 \\ 0 & 0 & 2.58239 & 0 & 0 \\ 0 & 0 & 0 & 1.20841 & 0 \\ 0 & 0 & 0 & 0 & 0.511218
  \end{pmatrix} \cdot \\
  \begin{pmatrix} 
    0.452438 & 0.336841 & 0.410894 & -0.456436 & -0.55197 \\ 0.403968 & -0.531238 & -0.483027 & 0.210155 & -0.526419 \\ 0.43523 & -0.601119 & 0.481498 & -0.122706 & 0.449817 \\ 0.463447 & 0.282982 & -0.586236 & -0.401113 & 0.447854 \\ 0.477391 & 0.403612 & 0.149459 &  0.756011 &  0.12371
  \end{pmatrix}^T
\end{math}
\caption{Singular Value Decomposition of the User Item Relationship Table}
\label{svdexample}
\end{figure}

\begin{figure}[h]
\begin{math}
    \begin{pmatrix}
    0.544178 & 0.0875457  \\ 0.330582 & 0.270665  \\ 0.517601 & 0.04377 \\ 0.438285 & 0.373564  \\ 0.366854 & -0.881822 
  \end{pmatrix} 
\end{math}

\begin{tikzpicture}[scale=3.0]
 \begin{scope}[thin,black,dot/.style={fill=blue,circle,inner sep=0pt,minimum size=3pt}]
   %x-y-Koordinatensystem
%  \draw[-latex] (90:-1) --++(90:2) node[left]{$y$};
%  \draw[-latex] (0:-1) --++(0:2) node[below]{$x$};
   \coordinate (x1) at (0, 0);
   \coordinate (x2) at (1, 0);
   \coordinate (y1) at (0, -1);
   \coordinate (y2) at (0, 1);
   \draw (x1) -- (x2) node[right]{$x$};
   \draw (y1) -- (y2) node[above]{$y$};
   \node [left] at (0,0) {$0.0$};
   \node [left] at (0,-1) {$-1.0$};
   \node [left] at (0,1) {$1.0$};
   \node [below] at (1,0) {$1.0$};


   \coordinate (user1) at (0.544178, 0.0875457); 
   \node[dot] at (user1);
   \node [anchor=west] at (user1) {$User1$};

   \coordinate (user2) at (0.330582, 0.270665); 
   \node[dot] at (user2);
   \node [anchor=west] at (user2) {$User2$};

   \coordinate (user3) at (0.517601, 0.04377); 
   \node[dot] at (user3);
   \node [anchor=north west] at (user3) {$User3$};

   \coordinate (user4) at (0.438285, 0.373564); 
   \node[dot] at (user4);
   \node [anchor=west] at (user4) {$User4$};

   \coordinate (user5) at (0.366854, -0.881822); 
   \node[dot] at (user5);
   \node [anchor=west] at (user5) {$User5$};

   

   
 \end{scope}
\end{tikzpicture}
\caption{Similar Users based on Singular Value Decomposition}
\label{svdgraph}
\end{figure}

\subsection{Everything together}
Add tags to all items, filter items by tag before using them for recommendations.
Calculate the average ratings, calculate the item similarities, calculate user predictions, calculate svd, calculate $U_k$, calculate user similarities.
Create on time recommendations.
\chapter{Implementation}
\section{Technologies}
% explain scala and why scala
% explain finagle
% explain triple store
\section{Architecture}
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [text width = 7.5em, text badly centered, draw, ellipse,fill=red!20, node distance=4cm,
    minimum height=2em]
    
\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [cloud] (webservice) {Webservice};
    \node [cloud, right of=webservice] (recommendation) {Recommendation Service};
    \node [cloud, above right of=recommendation] (item) {Item-Based Recommendation Service};
    \node [cloud, below right of=recommendation] (svd) {SVD-Based Recommendation Service};
    \node [cloud, below of=recommendation] (tag) {Tagging Service};
    \node [cloud, below of=tag] (rating) {Rating Service};
    \node [cloud, right of=tag] (stw) {Query STW Service};
%   \node [block] (init) {initialize model};
%   \node [cloud, left of=init] (expert) {expert};
%   \node [cloud, right of=init] (system) {system};
%   \node [block, below of=init] (identify) {identify candidate models};
%   \node [block, below of=identify] (evaluate) {evaluate candidate models};
%   \node [block, left of=evaluate, node distance=3cm] (update) {update model};
%   \node [decision, below of=evaluate] (decide) {is best candidate better?};
%   \node [block, below of=decide, node distance=3cm] (stop) {stop};
    % Draw edges
%   \path [line] (init) -- (identify);
%   \path [line] (identify) -- (evaluate);
%   \path [line] (evaluate) -- (decide);
%   \path [line] (decide) -| node [near start] {yes} (update);
%   \path [line] (update) |- (identify);
%   \path [line] (decide) -- node {no}(stop);
%   \path [line,dashed] (expert) -- (init);
%   \path [line,dashed] (system) -- (init);
%   \path [line,dashed] (system) |- (evaluate);
    \path [line] (webservice) -- (recommendation);
    \path [line] (recommendation) |- (item);
    \path [line] (recommendation) |- (svd);
    \path [line] (webservice) |- (tag);
    \path [line] (webservice) |- (rating);
\end{tikzpicture}

%Service oriented architecture why?
%communication diagram
%explain diagram
\section{Services}
%what is the service for 
%how to communicate with the service
\subsection{ItemBasedService}
\subsection{SVDBasedService}
\subsection{RecommendationService}
\subsection{LevenshteinDistanceService}
\subsection{TaggerService}
service architecture
\chapter{Evaluation}
\section{Rating}
%test with diffent view timings and scroll timings according to papers
\section{Tagging}
%test 10 words 100 words 500 words 1000 words with the service
%compare original levenshtein to new levenshtein
\section{Comparison Of Different Approaches}
\subsection{Performance of the Recommendations}
\subsection{Accuracy of the Recommendations}
\subsubsection{Item-Based}
\subsubsection{Singular Value Decomposition}
\subsubsection{Hybrid Of Item-Based and Singular Value Decomposition}
\chapter{Future Work}
\section{Rating System}
\section{Tagging Service}
Direct implementation of the deterministic levenshtein automata, table based approach.
Save levenshtein automatas from all \emph{STW Standard Thesaurus Economic} words with an appropriate datastructure.
\section{Recommendation System}

\appendix

\chapter{Erster Anhang}

\chapter{Zweiter Anhang}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                              %%
%%                     Literaturverzeichnis                     %%
%%                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{bib}       %% statt mybib Name der eigenen .bib-Datei einsetzen 
\bibliographystyle{plainnat}

\end{document}
